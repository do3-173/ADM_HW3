{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data collection\n",
    "\n",
    "For this homework, there is no provided dataset. Instead, you have to build your own. Your search engine will run on text documents. So, here\n",
    "we detail the procedure to follow for the data collection. We strongly suggest you work on different modules when implementing the required functions. For example, you may have a ```crawler.py``` module, a ```parser.py``` module, and a ```engine.py``` module: this is a good practice that improves readability in reporting and efficiency in de\\ploying the code. Be careful; you are likely dealing with exceptions and other possible issues! \n",
    "\n",
    "### 1.1. Get the list of master's degree courses\n",
    "\n",
    "We start with the list of courses to include in your corpus of documents. In particular, we focus on web scrapping the [MSc Degrees](https://www.findamasters.com/masters-degrees/msc-degrees/). Next, we want you to **collect the URL** associated with each site in the list from the previously collected list.\n",
    "The list is long and split into many pages. Therefore, we ask you to retrieve only the URLs of the places listed in **the first 400 pages** (each page has 15 courses, so you will end up with 6000 unique master's degree URLs).\n",
    "\n",
    "The output of this step is a `.txt` file whose single line corresponds to the master's URL.\n",
    "\n",
    "### 1.2. Crawl master's degree pages\n",
    "\n",
    "Once you get all the URLs in the first 400 pages of the list, you:\n",
    "\n",
    "1. Download the HTML corresponding to each of the collected URLs.\n",
    "2. After you collect a single page, immediately save its `HTML` in a file. In this way, if your program stops for any reason, you will not lose the data collected up to the stopping point.\n",
    "3. Organize the downloaded `HTML` pages into folders. Each folder will contain the `HTML` of the courses on page 1, page 2, ... of the list of master's programs.\n",
    "   \n",
    "__Tip__: Due to the large number of pages you should download, you can use some methods that can help you shorten the time. If you employed a particular process or approach, kindly describe it.\n",
    " \n",
    "### 1.3 Parse downloaded pages\n",
    "\n",
    "At this point, you should have all the HTML documents about the master's degree of interest, and you can start to extract specific information. The list of the information we desire for each course and their format is as follows:\n",
    "\n",
    "1. Course Name (to save as ```courseName```): string;\n",
    "2. University (to save as ```universityName```): string;\n",
    "3. Faculty (to save as ```facultyName```): string\n",
    "4. Full or Part Time (to save as ```isItFullTime```): string;\n",
    "5. Short Description (to save as ```description```): string;\n",
    "6. Start Date (to save as ```startDate```): string;\n",
    "7. Fees (to save as ```fees```): string;\n",
    "8. Modality (to save as ```modality```):string;\n",
    "9. Duration (to save as ```duration```):string;\n",
    "10. City (to save as ```city```): string;\n",
    "11. Country (to save as ```country```): string;\n",
    "12. Presence or online modality (to save as ```administration```): string;\n",
    "13. Link to the page (to save as ```url```): string.\n",
    "    \n",
    "<p align=\"center\">\n",
    "<img src=\"img/example.jpeg\" width = 1000>\n",
    "</p>\n",
    "This are the first rows of the scraped dataset:\n",
    "\n",
    "<div style=\"overflow-x:auto;\">\n",
    "<table>\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th>index</th>\n",
    "    <th>courseName</th>\n",
    "    <th>universityName</th>\n",
    "    <th>facultyName</th>\n",
    "    <th>isItFullTime</th>\n",
    "    <th>description</th>\n",
    "    <th>startDate</th>\n",
    "    <th>fees</th>\n",
    "    <th>modality</th>\n",
    "    <th>duration</th>\n",
    "    <th>city</th>\n",
    "    <th>country</th>\n",
    "    <th>administration</th>\n",
    "    <th>url</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td> Accounting and Finance - MSc</td>\n",
    "    <td>University of Leeds</td>\n",
    "    <td>Leeds University Business School</td>\n",
    "    <td>Full time</td>\n",
    "    <td>Businesses and governments rely on [...].</td>\n",
    "    <td>September</td>\n",
    "    <td>UK: £18,000 (Total) International: £34,750 (Total)</td>\n",
    "    <td>MSc</td>\n",
    "    <td>1 year full time</td>\n",
    "    <td>Leeds</td>\n",
    "    <td>United Kingdom</td>\n",
    "    <td>On Campus</td>\n",
    "    <td><a href=\"https://www.findamasters.com/masters-degrees/course/accounting-and-finance-msc/?i321d3232c3891\">Link</a></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td> Accounting, Accountability & Financial Management MSc</td>\n",
    "    <td>King’s College London</td>\n",
    "    <td>King’s Business School</td>\n",
    "    <td>Full time</td>\n",
    "    <td>Our Accounting, Accountability & Financial Management MSc course will provide [...].</td>\n",
    "    <td>September</td>\n",
    "    <td>Please see the university website for further information on fees for this course.</td>\n",
    "    <td>MSc</td>\n",
    "    <td>1 year FT</td>\n",
    "    <td>London</td>\n",
    "    <td>United Kingdom</td>\n",
    "    <td>On Campus</td>\n",
    "    <td><a href=\"https://www.findamasters.com/masters-degrees/course/accounting-accountability-and-financial-management-msc/?i132d7816c25522\">Link</a></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td> Accounting, Financial Management and Digital Business - MSc</td>\n",
    "    <td>University of Reading</td>\n",
    "    <td>Henley Business School</td>\n",
    "    <td>Full time</td>\n",
    "    <td>Embark on a professional accounting career [...].</td>\n",
    "    <td>September</td>\n",
    "    <td>Please see the university website for further information on fees for this course.</td>\n",
    "    <td>MSc</td>\n",
    "    <td>1 year full time</td>\n",
    "    <td>Reading</td>\n",
    "    <td>United Kingdom</td>\n",
    "    <td>On Campus</td>\n",
    "    <td><a href=\"https://www.findamasters.com/masters-degrees/course/accounting-financial-management-and-digital-business-msc/?i345d4286c351\">Link</a></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td> Addictions MSc</td>\n",
    "    <td>King’s College London</td>\n",
    "    <td>Institute of Psychiatry, Psychology and Neuroscience</td>\n",
    "    <td>Full time</td>\n",
    "    <td>Join us for an online session for prospective [...].</td>\n",
    "    <td>September</td>\n",
    "    <td>Please see the university website for further information on fees for this course.</td>\n",
    "    <td>MSc</td>\n",
    "    <td>One year FT</td>\n",
    "    <td>London</td>\n",
    "    <td>United Kingdom</td>\n",
    "    <td>On Campus</td>\n",
    "    <td><a href=\"https://www.findamasters.com/masters-degrees/course/addictions-msc/?i132d4318c27100\">Link</a></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>4</td>\n",
    "    <td> Advanced Chemical Engineering - MSc</td>\n",
    "    <td>University of Leeds</td>\n",
    "    <td>School of Chemical and Process Engineering</td>\n",
    "    <td>Full time</td>\n",
    "    <td>The Advanced Chemical Engineering MSc at Leeds [...].</td>\n",
    "    <td>September</td>\n",
    "    <td>UK: £13,750 (Total) International: £31,000 (Total)</td>\n",
    "    <td>MSc</td>\n",
    "    <td>1 year full time</td>\n",
    "    <td>Leeds</td>\n",
    "    <td>United Kingdom</td>\n",
    "    <td>On Campus</td>\n",
    "  </tr>\n",
    "  <!-- Add more rows here as needed -->\n",
    "</tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "\n",
    "For each master's degree, you create a `course_i.tsv` file of this structure:\n",
    "\n",
    "```\n",
    "courseName \\t universityName \\t  ... \\t url\n",
    "```\n",
    "\n",
    "If an information is missing, you just leave it as an empty string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Get the list of master's degree courses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we need to create the `crawler.py` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://www.findamasters.com/masters-degrees/msc-degrees/\"\n",
    "OUTPUT_FILE = \"masters_urls.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking out the URL and inspecting the website we find out the next piece of HTML code: `<a class=\"courseLink text-dark\" href=\"/masters-degrees/course/applied-economics-banking-and-financial-markets-online-msc/?i280d8352c56675\" title=\"Applied Economics (Banking and Financial Markets), online MSc at University of Bath Online, University of Bath\"><u>Applied Economics (Banking and Financial Markets), online MSc</u></a>`. The class `courseLink text-dark` will be helpful for us in getting all the course links. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_course_urls(page_url):\n",
    "    try:\n",
    "        response = requests.get(page_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    course_links = soup.find_all('a', class_='courseLink text-dark')\n",
    "    urls = ['https://www.findamasters.com/' + link['href'] for link in course_links if 'href' in link.attrs]\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n"
     ]
    }
   ],
   "source": [
    "for page in range(1):\n",
    "    if (page + 1) % 25 == 0 or page == 0:\n",
    "        print(f\"Scraping page {page + 1}\")\n",
    "    if page == 0:\n",
    "        page_url = f\"{BASE_URL}\"\n",
    "    else:\n",
    "        page_url = f\"{BASE_URL}?PG={page + 1}\"\n",
    "    urls = get_course_urls(page_url)\n",
    "    \n",
    "    if urls:\n",
    "        with open(OUTPUT_FILE, 'a') as file:\n",
    "            for url in urls:\n",
    "                file.write(f\"{url}\\n\")\n",
    "\n",
    "    # Sleeping to not have too many requests         \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Lines 6000\n"
     ]
    }
   ],
   "source": [
    "with open(OUTPUT_FILE, 'r') as file:\n",
    "    for count, line in enumerate(file):\n",
    "        pass\n",
    "# This needs to be 6000\n",
    "print('Total Lines', count + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Crawl master's degree pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_html(url, folder):\n",
    "    while True:\n",
    "        response = requests.get(url)\n",
    "        if \"Just a moment...\" in response.text:\n",
    "            # Sleeping before trying again (net issues, too many requests etc.)\n",
    "            time.sleep(3)\n",
    "        else:\n",
    "            filename = url.split('/')[-2] + url.split('/')[-1][2:6] + '.html'\n",
    "            path = os.path.join(folder, filename)\n",
    "            with open(path, 'w') as file:\n",
    "                file.write(response.text)\n",
    "            break \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb Cell 12\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m folder \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHTML/Page_\u001b[39m\u001b[39m{\u001b[39;00mpage_number\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m os\u001b[39m.\u001b[39mmakedirs(folder, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m download_html(url\u001b[39m.\u001b[39;49mstrip(), folder)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Sleeping to not have too many requests         \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb Cell 12\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mJust a moment...\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39mtext:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# Sleeping before trying again (net issues, too many requests etc.)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m3\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     filename \u001b[39m=\u001b[39m url\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m url\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m2\u001b[39m:\u001b[39m6\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.html\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('masters_urls.txt', 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "for i, url in enumerate(urls):\n",
    "    page_number = i // 15 + 1\n",
    "    folder = f\"HTML/Page_{page_number}\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    download_html(url.strip(), folder)\n",
    "\n",
    "    # Sleeping to not have too many requests         \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    course_name = soup.find('tag', id='courseName').text if soup.find('tag', id='courseName') else \"\"\n",
    "    university_name = soup.find('tag', id='universityName').text if soup.find('tag', id='universityName') else \"\"\n",
    "    faculty_name = soup.find('tag', id='facultyName').text if soup.find('tag', id='facultyName') else \"\"\n",
    "    is_full_time = soup.find('tag', id='isItFullTime').text if soup.find('tag', id='isItFullTime') else \"\"\n",
    "    description = soup.find('tag', id='description').text if soup.find('tag', id='description') else \"\"\n",
    "    start_date = soup.find('tag', id='startDate').text if soup.find('tag', id='startDate') else \"\"\n",
    "    fees = soup.find('tag', id='fees').text if soup.find('tag', id='fees') else \"\"\n",
    "    modality = soup.find('tag', id='modality').text if soup.find('tag', id='modality') else \"\"\n",
    "    duration = soup.find('tag', id='duration').text if soup.find('tag', id='duration') else \"\"\n",
    "    city = soup.find('tag', id='city').text if soup.find('tag', id='city') else \"\"\n",
    "    country = soup.find('tag', id='country').text if soup.find('tag', id='country') else \"\"\n",
    "    url = soup.select_one('link[rel=\"canonical\"]')['href'] if soup.select_one('link[rel=\"canonical\"]') else ''\n",
    "    course_info = {\n",
    "        'courseName': course_name,\n",
    "        'universityName': university_name,\n",
    "        'facultyName': faculty_name,\n",
    "        'isItFullTime': is_full_time,\n",
    "        'description': description,\n",
    "        'startDate': start_date,\n",
    "        'fees': fees,\n",
    "        'modality': modality,\n",
    "        ''\n",
    "        'url': url\n",
    "    }\n",
    "\n",
    "    return course_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_tsv(course_info, filename):\n",
    "    with open('TSV/' + filename, 'w', encoding='utf-8') as f:\n",
    "        for key, value in course_info.items():\n",
    "            f.write(f\"{value}\\t\")\n",
    "        f.write('\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated course_1.tsv\n",
      "Generated course_2.tsv\n",
      "Generated course_3.tsv\n",
      "Generated course_4.tsv\n",
      "Generated course_5.tsv\n",
      "Generated course_6.tsv\n",
      "Generated course_7.tsv\n",
      "Generated course_8.tsv\n",
      "Generated course_9.tsv\n",
      "Generated course_10.tsv\n",
      "Generated course_11.tsv\n",
      "Generated course_12.tsv\n",
      "Generated course_13.tsv\n",
      "Generated course_14.tsv\n",
      "Generated course_15.tsv\n",
      "Generated course_16.tsv\n",
      "Generated course_17.tsv\n",
      "Generated course_18.tsv\n",
      "Generated course_19.tsv\n",
      "Generated course_20.tsv\n",
      "Generated course_21.tsv\n",
      "Generated course_22.tsv\n",
      "Generated course_23.tsv\n",
      "Generated course_24.tsv\n",
      "Generated course_25.tsv\n",
      "Generated course_26.tsv\n",
      "Generated course_27.tsv\n",
      "Generated course_28.tsv\n",
      "Generated course_29.tsv\n",
      "Generated course_30.tsv\n",
      "Generated course_31.tsv\n",
      "Generated course_32.tsv\n",
      "Generated course_33.tsv\n",
      "Generated course_34.tsv\n",
      "Generated course_35.tsv\n",
      "Generated course_36.tsv\n",
      "Generated course_37.tsv\n",
      "Generated course_38.tsv\n",
      "Generated course_39.tsv\n",
      "Generated course_40.tsv\n",
      "Generated course_41.tsv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file_path, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     html_content \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     course_info \u001b[39m=\u001b[39m parse_html(html_content)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     tsv_filename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcourse_\u001b[39m\u001b[39m{\u001b[39;00mcourse_counter\u001b[39m}\u001b[39;00m\u001b[39m.tsv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     write_to_tsv(course_info, tsv_filename)\n",
      "\u001b[1;32m/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_html\u001b[39m(html_content):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(html_content, \u001b[39m'\u001b[39;49m\u001b[39mhtml.parser\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     url \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mselect_one(\u001b[39m'\u001b[39m\u001b[39mlink[rel=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcanonical\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mif\u001b[39;00m soup\u001b[39m.\u001b[39mselect_one(\u001b[39m'\u001b[39m\u001b[39mlink[rel=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcanonical\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     course_info \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39murl\u001b[39m\u001b[39m'\u001b[39m: url\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/edo/Sapienza/ADM/Assignments/ADM_HW3/data_collection.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     }\n",
      "File \u001b[0;32m~/anaconda3/envs/adm_hw3/lib/python3.11/site-packages/bs4/__init__.py:335\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39minitialize_soup(\u001b[39mself\u001b[39m)\n\u001b[1;32m    334\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feed()\n\u001b[1;32m    336\u001b[0m     success \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/adm_hw3/lib/python3.11/site-packages/bs4/__init__.py:478\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[39m# Convert the document to Unicode.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mreset()\n\u001b[0;32m--> 478\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mfeed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmarkup)\n\u001b[1;32m    479\u001b[0m \u001b[39m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendData()\n",
      "File \u001b[0;32m~/anaconda3/envs/adm_hw3/lib/python3.11/site-packages/bs4/builder/_htmlparser.py:380\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    378\u001b[0m parser\u001b[39m.\u001b[39msoup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoup\n\u001b[1;32m    379\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     parser\u001b[39m.\u001b[39;49mfeed(markup)\n\u001b[1;32m    381\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    382\u001b[0m     \u001b[39m# html.parser raises AssertionError in rare cases to\u001b[39;00m\n\u001b[1;32m    383\u001b[0m     \u001b[39m# indicate a fatal problem with the markup, especially\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[39m# when there's an error in the doctype declaration.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[39mraise\u001b[39;00m ParserRejectedMarkup(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/adm_hw3/lib/python3.11/html/parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39mas you want (may include '\\n').\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m+\u001b[39m data\n\u001b[0;32m--> 110\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgoahead(\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/adm_hw3/lib/python3.11/html/parser.py:170\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m startswith(\u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m, i):\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m starttagopen\u001b[39m.\u001b[39mmatch(rawdata, i): \u001b[39m# < + letter\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m         k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_starttag(i)\n\u001b[1;32m    171\u001b[0m     \u001b[39melif\u001b[39;00m startswith(\u001b[39m\"\u001b[39m\u001b[39m</\u001b[39m\u001b[39m\"\u001b[39m, i):\n\u001b[1;32m    172\u001b[0m         k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_endtag(i)\n",
      "File \u001b[0;32m~/anaconda3/envs/adm_hw3/lib/python3.11/html/parser.py:337\u001b[0m, in \u001b[0;36mHTMLParser.parse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_startendtag(tag, attrs)\n\u001b[1;32m    336\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 337\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_starttag(tag, attrs)\n\u001b[1;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m tag \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mCDATA_CONTENT_ELEMENTS:\n\u001b[1;32m    339\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_cdata_mode(tag)\n",
      "File \u001b[0;32m~/anaconda3/envs/adm_hw3/lib/python3.11/site-packages/bs4/builder/_htmlparser.py:141\u001b[0m, in \u001b[0;36mBeautifulSoupHTMLParser.handle_starttag\u001b[0;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[1;32m    136\u001b[0m sourceline, sourcepos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetpos()\n\u001b[1;32m    137\u001b[0m tag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoup\u001b[39m.\u001b[39mhandle_starttag(\n\u001b[1;32m    138\u001b[0m     name, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, attr_dict, sourceline\u001b[39m=\u001b[39msourceline,\n\u001b[1;32m    139\u001b[0m     sourcepos\u001b[39m=\u001b[39msourcepos\n\u001b[1;32m    140\u001b[0m )\n\u001b[0;32m--> 141\u001b[0m \u001b[39mif\u001b[39;00m tag \u001b[39mand\u001b[39;00m tag\u001b[39m.\u001b[39mis_empty_element \u001b[39mand\u001b[39;00m handle_empty_element:\n\u001b[1;32m    142\u001b[0m     \u001b[39m# Unlike other parsers, html.parser doesn't send separate end tag\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[39m# events for empty-element tags. (It's handled in\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[39m# handle_startendtag, but only if the original markup looked like\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[39m# <tag/>.)\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[39m# So we need to call handle_endtag() ourselves. Since we\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     \u001b[39m# know the start event is identical to the end event, we\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     \u001b[39m# don't want handle_endtag() to cross off any previous end\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[39m# events for tags of this name.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_endtag(name, check_already_closed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    153\u001b[0m     \u001b[39m# But we might encounter an explicit closing tag for this tag\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[39m# later on. If so, we want to ignore it.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/adm_hw3/lib/python3.11/site-packages/bs4/element.py:1586\u001b[0m, in \u001b[0;36mTag.__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__contains__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m   1584\u001b[0m     \u001b[39mreturn\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontents\n\u001b[0;32m-> 1586\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__bool__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1587\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mA tag is non-None even if it has no contents.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1588\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "root_path = 'HTML/'\n",
    "\n",
    "course_counter = 1\n",
    "for root, dirs, files in os.walk(root_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.html'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                html_content = f.read()\n",
    "                course_info = parse_html(html_content)\n",
    "                \n",
    "                tsv_filename = f\"course_{course_counter}.tsv\"\n",
    "                write_to_tsv(course_info, tsv_filename)\n",
    "                print(f\"Generated {tsv_filename}\")  # Optional, for progress tracking\n",
    "                \n",
    "                course_counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adm_hw3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

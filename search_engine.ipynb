{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search Engine\n",
    "\n",
    "Now, we want to create two different Search Engines that, given as input a query, return the courses that match the query.\n",
    "\n",
    "### 2.0 Preprocessing \n",
    "\n",
    "### 2.0.0)  Preprocessing the text\n",
    "\n",
    "First, you must pre-process all the information collected for each MSc by:\n",
    "\n",
    "1. Removing stopwords\n",
    "2. Removing punctuation\n",
    "3. Stemming\n",
    "4. Anything else you think it's needed\n",
    "   \n",
    "For this purpose, you can use the [`nltk library](https://www.nltk.org/).\n",
    "\n",
    "### 2.0.1) Preprocessing the fees column\n",
    "\n",
    "Moreover, we want the field ```fees``` to collect numeric information. As you will see, you scraped textual information for this attribute in the dataset: sketch whatever method you need (using regex, for example, to find currency symbol) to collect information and, in case of multiple information, retrieve only the highest fees. Finally, once you have collected numerical information, you likely will have different currencies: this can be chaotic, so let chatGPT guide you in the choice and deployment of an API to convert this column to a common currency of your choice (it can be USD, EUR or whatever you want). Ultimately, you will have a ```float``` column renamed ```fees (CHOSEN COMMON CURRENCY)```.\n",
    "\n",
    "### 2.1. Conjunctive query\n",
    "For the first version of the search engine, we narrowed our interest to the __description__ of each course. It means that you will evaluate queries only concerning the course's description.\n",
    "\n",
    "### 2.1.1) Create your index!\n",
    "\n",
    "Before building the index, \n",
    "* Create a file named `vocabulary`, in the format you prefer, that maps each word to an integer (`term_id`).\n",
    "\n",
    "Then, the first brick of your homework is to create the Inverted Index. It will be a dictionary in this format:\n",
    "\n",
    "```\n",
    "{\n",
    "term_id_1:[document_1, document_2, document_4],\n",
    "term_id_2:[document_1, document_3, document_5, document_6],\n",
    "...}\n",
    "```\n",
    "where _document\\_i_ is the *id* of a document that contains that specific word.\n",
    "\n",
    "__Hint:__ Since you do not want to compute the inverted index every time you use the Search Engine, it is worth thinking about storing it in a separate file and loading it in memory when needed.\n",
    "\n",
    "#### 2.1.2) Execute the query\n",
    "Given a query input by the user, for example:\n",
    "\n",
    "```\n",
    "advanced knowledge\n",
    "```\n",
    "\n",
    "The Search Engine is supposed to return a list of documents.\n",
    "\n",
    "##### What documents do we want?\n",
    "Since we are dealing with conjunctive queries (AND), each returned document should contain all the words in the query.\n",
    "The final output of the query must return, if present, the following information for each of the selected documents:\n",
    "\n",
    "* `courseName`\n",
    "* `universityName`\n",
    "* `description`\n",
    "* `URL`\n",
    "\n",
    "__Example Output__ for ```advanced knowledge```: (please note that our examples are made on a small batch of the full dataset)\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"img/output1.png\" width = 1000>\n",
    "</p>\n",
    "\n",
    "If everything works well in this step, you can go to the next point and make your Search Engine more complex and better at answering queries.\n",
    "\n",
    "\n",
    "### 2.2) Conjunctive query & Ranking score\n",
    "\n",
    "For the second search engine, given a query, we want to get the *top-k* (the choice of *k* it's up to you!) documents related to the query. In particular:\n",
    "\n",
    "* Find all the documents that contain all the words in the query.\n",
    "* Sort them by their similarity with the query.\n",
    "* Return in output *k* documents, or all the documents with non-zero similarity with the query when the results are less than _k_. You __must__ use a heap data structure (you can use Python libraries) for maintaining the *top-k* documents.\n",
    "\n",
    "To solve this task, you must use the *tfIdf* score and the _Cosine similarity_. The field to consider is still the `description`. Let's see how.\n",
    "\n",
    "\n",
    "#### 2.2.1) Inverted index\n",
    "Your second Inverted Index must be of this format:\n",
    "\n",
    "```\n",
    "{\n",
    "term_id_1:[(document1, tfIdf_{term,document1}), (document2, tfIdf_{term,document2}), (document4, tfIdf_{term,document4}), ...],\n",
    "term_id_2:[(document1, tfIdf_{term,document1}), (document3, tfIdf_{term,document3}), (document5, tfIdf_{term,document5}), (document6, tfIdf_{term,document6}), ...],\n",
    "...}\n",
    "```\n",
    "\n",
    "Practically, for each word, you want the list of documents in which it is contained and the relative *tfIdf* score.\n",
    "\n",
    "__Tip__: *TfIdf* values are invariant for the query. Due to this reason, you can precalculate and store them accordingly.\n",
    "\n",
    "#### 2.2.2) Execute the query\n",
    "\n",
    "In this new setting, given a query, you get the proper documents (i.e., those containing all the query's words) and sort them according to their similarity to the query. For this purpose, as the scoring function, we will use the Cosine Similarity concerning the *tfIdf* representations of the documents.\n",
    "\n",
    "Given a query input by the user, for example:\n",
    "```\n",
    "advanced knowledge\n",
    "```\n",
    "The search engine is supposed to return a list of documents, __ranked__ by their Cosine Similarity to the query entered in the input.\n",
    "\n",
    "More precisely, the output must contain:\n",
    "* `courseName`\n",
    "* `universityName`\n",
    "* `description`\n",
    "* `URL`\n",
    "* The similarity score of the documents with respect to the query (float value between 0 and 1)\n",
    "  \n",
    "__Example Output__ for ```advanced knowledge```:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"img/output2.png\" width = 1000>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/edo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/edo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# NLTK Download\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>facultyName</th>\n",
       "      <th>isItFullTime</th>\n",
       "      <th>description</th>\n",
       "      <th>startDate</th>\n",
       "      <th>fees</th>\n",
       "      <th>modality</th>\n",
       "      <th>duration</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>administration</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computer Science - MSc</td>\n",
       "      <td>University of Hertfordshire</td>\n",
       "      <td>School of Physics, Engineering and Computer Sc...</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Why choose Herts?Industry Accreditation: Accre...</td>\n",
       "      <td>See Course</td>\n",
       "      <td>UK Students  Full time: £9450 for the 2022/202...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full-time, 15 months full-time, 3 years...</td>\n",
       "      <td>Hatfield</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computer Science (Cyber Security) - MSc</td>\n",
       "      <td>Staffordshire University</td>\n",
       "      <td>School of Digital, Technologies and Arts</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Join the fight against malicious programs and ...</td>\n",
       "      <td>September</td>\n",
       "      <td>Find the specific fees for your chosen program...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>13 months - 25 months</td>\n",
       "      <td>Stoke on Trent</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Computer Science (Data Science) - MSc</td>\n",
       "      <td>Trinity College Dublin</td>\n",
       "      <td>School of Computer Science &amp; Statistics</td>\n",
       "      <td>Full time</td>\n",
       "      <td>The MSc in Computer Science is an exciting one...</td>\n",
       "      <td>September</td>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full-time</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Computer Science (by Research) - MSc</td>\n",
       "      <td>Lancaster University</td>\n",
       "      <td>School of Computing and Communications</td>\n",
       "      <td>Full time</td>\n",
       "      <td>The MSc by Research programme can be tailored ...</td>\n",
       "      <td>See Course</td>\n",
       "      <td>Please see the university website for further ...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>12 months full-time, 24 months part time</td>\n",
       "      <td>Lancaster</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Computer Science (Computer Networks and Securi...</td>\n",
       "      <td>Staffordshire University</td>\n",
       "      <td>School of Digital, Technologies and Arts</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Secure your future career with our Computer Sc...</td>\n",
       "      <td>September</td>\n",
       "      <td>Find the specific fees for your chosen program...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>13 months - 25 months</td>\n",
       "      <td>Stoke on Trent</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>On Campus</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          courseName  \\\n",
       "0                             Computer Science - MSc   \n",
       "1            Computer Science (Cyber Security) - MSc   \n",
       "2              Computer Science (Data Science) - MSc   \n",
       "3               Computer Science (by Research) - MSc   \n",
       "4  Computer Science (Computer Networks and Securi...   \n",
       "\n",
       "                universityName  \\\n",
       "0  University of Hertfordshire   \n",
       "1     Staffordshire University   \n",
       "2       Trinity College Dublin   \n",
       "3         Lancaster University   \n",
       "4     Staffordshire University   \n",
       "\n",
       "                                         facultyName isItFullTime  \\\n",
       "0  School of Physics, Engineering and Computer Sc...    Full time   \n",
       "1           School of Digital, Technologies and Arts    Full time   \n",
       "2            School of Computer Science & Statistics    Full time   \n",
       "3             School of Computing and Communications    Full time   \n",
       "4           School of Digital, Technologies and Arts    Full time   \n",
       "\n",
       "                                         description   startDate  \\\n",
       "0  Why choose Herts?Industry Accreditation: Accre...  See Course   \n",
       "1  Join the fight against malicious programs and ...   September   \n",
       "2  The MSc in Computer Science is an exciting one...   September   \n",
       "3  The MSc by Research programme can be tailored ...  See Course   \n",
       "4  Secure your future career with our Computer Sc...   September   \n",
       "\n",
       "                                                fees modality  \\\n",
       "0  UK Students  Full time: £9450 for the 2022/202...      MSc   \n",
       "1  Find the specific fees for your chosen program...      MSc   \n",
       "2  Please see the university website for further ...      MSc   \n",
       "3  Please see the university website for further ...      MSc   \n",
       "4  Find the specific fees for your chosen program...      MSc   \n",
       "\n",
       "                                            duration            city  \\\n",
       "0  1 year full-time, 15 months full-time, 3 years...        Hatfield   \n",
       "1                              13 months - 25 months  Stoke on Trent   \n",
       "2                                   1 year full-time          Dublin   \n",
       "3           12 months full-time, 24 months part time       Lancaster   \n",
       "4                              13 months - 25 months  Stoke on Trent   \n",
       "\n",
       "          country administration  \\\n",
       "0  United Kingdom      On Campus   \n",
       "1  United Kingdom      On Campus   \n",
       "2         Ireland      On Campus   \n",
       "3  United Kingdom      On Campus   \n",
       "4  United Kingdom      On Campus   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.findamasters.com/masters-degrees/c...  \n",
       "1  https://www.findamasters.com/masters-degrees/c...  \n",
       "2  https://www.findamasters.com/masters-degrees/c...  \n",
       "3  https://www.findamasters.com/masters-degrees/c...  \n",
       "4  https://www.findamasters.com/masters-degrees/c...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the TSV data\n",
    "df = pd.read_csv(\"TSV/course_1.tsv\", sep=\"\\t\", index_col=False)\n",
    "\n",
    "for i in range(2, 6001):\n",
    "    try:\n",
    "        df1 = pd.read_csv(\n",
    "            \"TSV/course_\" + str(i) + \".tsv\",\n",
    "            sep=\"\\t\",\n",
    "            index_col=False,\n",
    "        )\n",
    "        df1.index += i - 1\n",
    "        df = pd.concat([df, df1])\n",
    "    except Exception as e:\n",
    "        print(i)\n",
    "        print(\"Error: \", e)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopless(text):\n",
    "    if isinstance(text, str):\n",
    "        words = word_tokenize(text)\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "        return \" \".join(filtered_words)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3490/3404425599.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_preprocessed = df.applymap(stopless)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>facultyName</th>\n",
       "      <th>isItFullTime</th>\n",
       "      <th>description</th>\n",
       "      <th>startDate</th>\n",
       "      <th>fees</th>\n",
       "      <th>modality</th>\n",
       "      <th>duration</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>administration</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computer Science - MSc</td>\n",
       "      <td>University Hertfordshire</td>\n",
       "      <td>School Physics , Engineering Computer Science</td>\n",
       "      <td>Full time</td>\n",
       "      <td>choose Herts ? Industry Accreditation : Accred...</td>\n",
       "      <td>See Course</td>\n",
       "      <td>UK Students Full time : £9450 2022/2023 academ...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full-time , 15 months full-time , 3 yea...</td>\n",
       "      <td>Hatfield</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Campus</td>\n",
       "      <td>https : //www.findamasters.com/masters-degrees...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computer Science ( Cyber Security ) - MSc</td>\n",
       "      <td>Staffordshire University</td>\n",
       "      <td>School Digital , Technologies Arts</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Join fight malicious programs cybercrime Compu...</td>\n",
       "      <td>September</td>\n",
       "      <td>Find specific fees chosen programme website</td>\n",
       "      <td>MSc</td>\n",
       "      <td>13 months - 25 months</td>\n",
       "      <td>Stoke Trent</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Campus</td>\n",
       "      <td>https : //www.findamasters.com/masters-degrees...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Computer Science ( Data Science ) - MSc</td>\n",
       "      <td>Trinity College Dublin</td>\n",
       "      <td>School Computer Science &amp; Statistics</td>\n",
       "      <td>Full time</td>\n",
       "      <td>MSc Computer Science exciting one-calendar-yea...</td>\n",
       "      <td>September</td>\n",
       "      <td>Please see university website information fees...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full-time</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Campus</td>\n",
       "      <td>https : //www.findamasters.com/masters-degrees...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Computer Science ( Research ) - MSc</td>\n",
       "      <td>Lancaster University</td>\n",
       "      <td>School Computing Communications</td>\n",
       "      <td>Full time</td>\n",
       "      <td>MSc Research programme tailored individual res...</td>\n",
       "      <td>See Course</td>\n",
       "      <td>Please see university website information fees...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>12 months full-time , 24 months part time</td>\n",
       "      <td>Lancaster</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Campus</td>\n",
       "      <td>https : //www.findamasters.com/masters-degrees...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Computer Science ( Computer Networks Security ...</td>\n",
       "      <td>Staffordshire University</td>\n",
       "      <td>School Digital , Technologies Arts</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Secure future career Computer Science ( Comput...</td>\n",
       "      <td>September</td>\n",
       "      <td>Find specific fees chosen programme website</td>\n",
       "      <td>MSc</td>\n",
       "      <td>13 months - 25 months</td>\n",
       "      <td>Stoke Trent</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Campus</td>\n",
       "      <td>https : //www.findamasters.com/masters-degrees...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          courseName  \\\n",
       "0                             Computer Science - MSc   \n",
       "1          Computer Science ( Cyber Security ) - MSc   \n",
       "2            Computer Science ( Data Science ) - MSc   \n",
       "3                Computer Science ( Research ) - MSc   \n",
       "4  Computer Science ( Computer Networks Security ...   \n",
       "\n",
       "             universityName                                    facultyName  \\\n",
       "0  University Hertfordshire  School Physics , Engineering Computer Science   \n",
       "1  Staffordshire University             School Digital , Technologies Arts   \n",
       "2    Trinity College Dublin           School Computer Science & Statistics   \n",
       "3      Lancaster University                School Computing Communications   \n",
       "4  Staffordshire University             School Digital , Technologies Arts   \n",
       "\n",
       "  isItFullTime                                        description   startDate  \\\n",
       "0    Full time  choose Herts ? Industry Accreditation : Accred...  See Course   \n",
       "1    Full time  Join fight malicious programs cybercrime Compu...   September   \n",
       "2    Full time  MSc Computer Science exciting one-calendar-yea...   September   \n",
       "3    Full time  MSc Research programme tailored individual res...  See Course   \n",
       "4    Full time  Secure future career Computer Science ( Comput...   September   \n",
       "\n",
       "                                                fees modality  \\\n",
       "0  UK Students Full time : £9450 2022/2023 academ...      MSc   \n",
       "1        Find specific fees chosen programme website      MSc   \n",
       "2  Please see university website information fees...      MSc   \n",
       "3  Please see university website information fees...      MSc   \n",
       "4        Find specific fees chosen programme website      MSc   \n",
       "\n",
       "                                            duration         city  \\\n",
       "0  1 year full-time , 15 months full-time , 3 yea...     Hatfield   \n",
       "1                              13 months - 25 months  Stoke Trent   \n",
       "2                                   1 year full-time       Dublin   \n",
       "3          12 months full-time , 24 months part time    Lancaster   \n",
       "4                              13 months - 25 months  Stoke Trent   \n",
       "\n",
       "          country administration  \\\n",
       "0  United Kingdom         Campus   \n",
       "1  United Kingdom         Campus   \n",
       "2         Ireland         Campus   \n",
       "3  United Kingdom         Campus   \n",
       "4  United Kingdom         Campus   \n",
       "\n",
       "                                                 url  \n",
       "0  https : //www.findamasters.com/masters-degrees...  \n",
       "1  https : //www.findamasters.com/masters-degrees...  \n",
       "2  https : //www.findamasters.com/masters-degrees...  \n",
       "3  https : //www.findamasters.com/masters-degrees...  \n",
       "4  https : //www.findamasters.com/masters-degrees...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed = df.applymap(stopless)\n",
    "df_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punct(text):\n",
    "    if isinstance(text, str):\n",
    "        words = word_tokenize(text)\n",
    "        filtered_words = [\n",
    "            word for word in words if word.lower() not in string.punctuation\n",
    "        ]\n",
    "        return \" \".join(filtered_words)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3490/3437730669.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_preprocessed = df_preprocessed.applymap(punct)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>facultyName</th>\n",
       "      <th>isItFullTime</th>\n",
       "      <th>description</th>\n",
       "      <th>startDate</th>\n",
       "      <th>fees</th>\n",
       "      <th>modality</th>\n",
       "      <th>duration</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>administration</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computer Science MSc</td>\n",
       "      <td>University Hertfordshire</td>\n",
       "      <td>School Physics Engineering Computer Science</td>\n",
       "      <td>Full time</td>\n",
       "      <td>choose Herts Industry Accreditation Accredited...</td>\n",
       "      <td>See Course</td>\n",
       "      <td>UK Students Full time £9450 2022/2023 academic...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full-time 15 months full-time 3 years p...</td>\n",
       "      <td>Hatfield</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Campus</td>\n",
       "      <td>https //www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computer Science Cyber Security MSc</td>\n",
       "      <td>Staffordshire University</td>\n",
       "      <td>School Digital Technologies Arts</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Join fight malicious programs cybercrime Compu...</td>\n",
       "      <td>September</td>\n",
       "      <td>Find specific fees chosen programme website</td>\n",
       "      <td>MSc</td>\n",
       "      <td>13 months 25 months</td>\n",
       "      <td>Stoke Trent</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Campus</td>\n",
       "      <td>https //www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Computer Science Data Science MSc</td>\n",
       "      <td>Trinity College Dublin</td>\n",
       "      <td>School Computer Science Statistics</td>\n",
       "      <td>Full time</td>\n",
       "      <td>MSc Computer Science exciting one-calendar-yea...</td>\n",
       "      <td>September</td>\n",
       "      <td>Please see university website information fees...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>1 year full-time</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>Campus</td>\n",
       "      <td>https //www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Computer Science Research MSc</td>\n",
       "      <td>Lancaster University</td>\n",
       "      <td>School Computing Communications</td>\n",
       "      <td>Full time</td>\n",
       "      <td>MSc Research programme tailored individual res...</td>\n",
       "      <td>See Course</td>\n",
       "      <td>Please see university website information fees...</td>\n",
       "      <td>MSc</td>\n",
       "      <td>12 months full-time 24 months part time</td>\n",
       "      <td>Lancaster</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Campus</td>\n",
       "      <td>https //www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Computer Science Computer Networks Security MSc</td>\n",
       "      <td>Staffordshire University</td>\n",
       "      <td>School Digital Technologies Arts</td>\n",
       "      <td>Full time</td>\n",
       "      <td>Secure future career Computer Science Computer...</td>\n",
       "      <td>September</td>\n",
       "      <td>Find specific fees chosen programme website</td>\n",
       "      <td>MSc</td>\n",
       "      <td>13 months 25 months</td>\n",
       "      <td>Stoke Trent</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Campus</td>\n",
       "      <td>https //www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        courseName            universityName  \\\n",
       "0                             Computer Science MSc  University Hertfordshire   \n",
       "1              Computer Science Cyber Security MSc  Staffordshire University   \n",
       "2                Computer Science Data Science MSc    Trinity College Dublin   \n",
       "3                    Computer Science Research MSc      Lancaster University   \n",
       "4  Computer Science Computer Networks Security MSc  Staffordshire University   \n",
       "\n",
       "                                   facultyName isItFullTime  \\\n",
       "0  School Physics Engineering Computer Science    Full time   \n",
       "1             School Digital Technologies Arts    Full time   \n",
       "2           School Computer Science Statistics    Full time   \n",
       "3              School Computing Communications    Full time   \n",
       "4             School Digital Technologies Arts    Full time   \n",
       "\n",
       "                                         description   startDate  \\\n",
       "0  choose Herts Industry Accreditation Accredited...  See Course   \n",
       "1  Join fight malicious programs cybercrime Compu...   September   \n",
       "2  MSc Computer Science exciting one-calendar-yea...   September   \n",
       "3  MSc Research programme tailored individual res...  See Course   \n",
       "4  Secure future career Computer Science Computer...   September   \n",
       "\n",
       "                                                fees modality  \\\n",
       "0  UK Students Full time £9450 2022/2023 academic...      MSc   \n",
       "1        Find specific fees chosen programme website      MSc   \n",
       "2  Please see university website information fees...      MSc   \n",
       "3  Please see university website information fees...      MSc   \n",
       "4        Find specific fees chosen programme website      MSc   \n",
       "\n",
       "                                            duration         city  \\\n",
       "0  1 year full-time 15 months full-time 3 years p...     Hatfield   \n",
       "1                                13 months 25 months  Stoke Trent   \n",
       "2                                   1 year full-time       Dublin   \n",
       "3            12 months full-time 24 months part time    Lancaster   \n",
       "4                                13 months 25 months  Stoke Trent   \n",
       "\n",
       "          country administration  \\\n",
       "0  United Kingdom         Campus   \n",
       "1  United Kingdom         Campus   \n",
       "2         Ireland         Campus   \n",
       "3  United Kingdom         Campus   \n",
       "4  United Kingdom         Campus   \n",
       "\n",
       "                                                 url  \n",
       "0  https //www.findamasters.com/masters-degrees/c...  \n",
       "1  https //www.findamasters.com/masters-degrees/c...  \n",
       "2  https //www.findamasters.com/masters-degrees/c...  \n",
       "3  https //www.findamasters.com/masters-degrees/c...  \n",
       "4  https //www.findamasters.com/masters-degrees/c...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed = df_preprocessed.applymap(punct)\n",
    "df_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    if isinstance(text, str):\n",
    "        ps = PorterStemmer()\n",
    "        words = word_tokenize(text)\n",
    "        stemmed_words = [ps.stem(word) for word in words]\n",
    "        return \" \".join(stemmed_words)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3490/3393340246.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_preprocessed = df_preprocessed.applymap(stem)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>facultyName</th>\n",
       "      <th>isItFullTime</th>\n",
       "      <th>description</th>\n",
       "      <th>startDate</th>\n",
       "      <th>fees</th>\n",
       "      <th>modality</th>\n",
       "      <th>duration</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>administration</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comput scienc msc</td>\n",
       "      <td>univers hertfordshir</td>\n",
       "      <td>school physic engin comput scienc</td>\n",
       "      <td>full time</td>\n",
       "      <td>choos hert industri accredit accredit british ...</td>\n",
       "      <td>see cours</td>\n",
       "      <td>uk student full time £9450 2022/2023 academ ye...</td>\n",
       "      <td>msc</td>\n",
       "      <td>1 year full-tim 15 month full-tim 3 year part-tim</td>\n",
       "      <td>hatfield</td>\n",
       "      <td>unit kingdom</td>\n",
       "      <td>campu</td>\n",
       "      <td>http //www.findamasters.com/masters-degrees/co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comput scienc cyber secur msc</td>\n",
       "      <td>staffordshir univers</td>\n",
       "      <td>school digit technolog art</td>\n",
       "      <td>full time</td>\n",
       "      <td>join fight malici program cybercrim comput sci...</td>\n",
       "      <td>septemb</td>\n",
       "      <td>find specif fee chosen programm websit</td>\n",
       "      <td>msc</td>\n",
       "      <td>13 month 25 month</td>\n",
       "      <td>stoke trent</td>\n",
       "      <td>unit kingdom</td>\n",
       "      <td>campu</td>\n",
       "      <td>http //www.findamasters.com/masters-degrees/co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comput scienc data scienc msc</td>\n",
       "      <td>triniti colleg dublin</td>\n",
       "      <td>school comput scienc statist</td>\n",
       "      <td>full time</td>\n",
       "      <td>msc comput scienc excit one-calendar-year prog...</td>\n",
       "      <td>septemb</td>\n",
       "      <td>pleas see univers websit inform fee cours</td>\n",
       "      <td>msc</td>\n",
       "      <td>1 year full-tim</td>\n",
       "      <td>dublin</td>\n",
       "      <td>ireland</td>\n",
       "      <td>campu</td>\n",
       "      <td>http //www.findamasters.com/masters-degrees/co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comput scienc research msc</td>\n",
       "      <td>lancast univers</td>\n",
       "      <td>school comput commun</td>\n",
       "      <td>full time</td>\n",
       "      <td>msc research programm tailor individu research...</td>\n",
       "      <td>see cours</td>\n",
       "      <td>pleas see univers websit inform fee cours</td>\n",
       "      <td>msc</td>\n",
       "      <td>12 month full-tim 24 month part time</td>\n",
       "      <td>lancast</td>\n",
       "      <td>unit kingdom</td>\n",
       "      <td>campu</td>\n",
       "      <td>http //www.findamasters.com/masters-degrees/co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comput scienc comput network secur msc</td>\n",
       "      <td>staffordshir univers</td>\n",
       "      <td>school digit technolog art</td>\n",
       "      <td>full time</td>\n",
       "      <td>secur futur career comput scienc comput networ...</td>\n",
       "      <td>septemb</td>\n",
       "      <td>find specif fee chosen programm websit</td>\n",
       "      <td>msc</td>\n",
       "      <td>13 month 25 month</td>\n",
       "      <td>stoke trent</td>\n",
       "      <td>unit kingdom</td>\n",
       "      <td>campu</td>\n",
       "      <td>http //www.findamasters.com/masters-degrees/co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               courseName         universityName  \\\n",
       "0                       comput scienc msc   univers hertfordshir   \n",
       "1           comput scienc cyber secur msc   staffordshir univers   \n",
       "2           comput scienc data scienc msc  triniti colleg dublin   \n",
       "3              comput scienc research msc        lancast univers   \n",
       "4  comput scienc comput network secur msc   staffordshir univers   \n",
       "\n",
       "                         facultyName isItFullTime  \\\n",
       "0  school physic engin comput scienc    full time   \n",
       "1         school digit technolog art    full time   \n",
       "2       school comput scienc statist    full time   \n",
       "3               school comput commun    full time   \n",
       "4         school digit technolog art    full time   \n",
       "\n",
       "                                         description  startDate  \\\n",
       "0  choos hert industri accredit accredit british ...  see cours   \n",
       "1  join fight malici program cybercrim comput sci...    septemb   \n",
       "2  msc comput scienc excit one-calendar-year prog...    septemb   \n",
       "3  msc research programm tailor individu research...  see cours   \n",
       "4  secur futur career comput scienc comput networ...    septemb   \n",
       "\n",
       "                                                fees modality  \\\n",
       "0  uk student full time £9450 2022/2023 academ ye...      msc   \n",
       "1             find specif fee chosen programm websit      msc   \n",
       "2          pleas see univers websit inform fee cours      msc   \n",
       "3          pleas see univers websit inform fee cours      msc   \n",
       "4             find specif fee chosen programm websit      msc   \n",
       "\n",
       "                                            duration         city  \\\n",
       "0  1 year full-tim 15 month full-tim 3 year part-tim     hatfield   \n",
       "1                                  13 month 25 month  stoke trent   \n",
       "2                                    1 year full-tim       dublin   \n",
       "3               12 month full-tim 24 month part time      lancast   \n",
       "4                                  13 month 25 month  stoke trent   \n",
       "\n",
       "        country administration  \\\n",
       "0  unit kingdom          campu   \n",
       "1  unit kingdom          campu   \n",
       "2       ireland          campu   \n",
       "3  unit kingdom          campu   \n",
       "4  unit kingdom          campu   \n",
       "\n",
       "                                                 url  \n",
       "0  http //www.findamasters.com/masters-degrees/co...  \n",
       "1  http //www.findamasters.com/masters-degrees/co...  \n",
       "2  http //www.findamasters.com/masters-degrees/co...  \n",
       "3  http //www.findamasters.com/masters-degrees/co...  \n",
       "4  http //www.findamasters.com/masters-degrees/co...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessed = df_preprocessed.applymap(stem)\n",
    "df_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing special characters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0.1) Preprocessing the fees column\n",
    "\n",
    "Moreover, we want the field ```fees``` to collect numeric information. As you will see, you scraped textual information for this attribute in the dataset: sketch whatever method you need (using regex, for example, to find currency symbol) to collect information and, in case of multiple information, retrieve only the highest fees. Finally, once you have collected numerical information, you likely will have different currencies: this can be chaotic, so let chatGPT guide you in the choice and deployment of an API to convert this column to a common currency of your choice (it can be USD, EUR or whatever you want). Ultimately, you will have a ```float``` column renamed ```fees (CHOSEN COMMON CURRENCY)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function that will take in a string fee and return just the numeric part of it as a float\n",
    "def convert_to_numeric(value):\n",
    "    # Removing currency symbols, commas, and spaces\n",
    "    value = re.sub(r\"eur|sek|chf|gbp|rmb|jpy|qr|[£€]|,|\\s\", \"\", value)\n",
    "    return float(value)\n",
    "\n",
    "\n",
    "def find_fees(text):\n",
    "    if isinstance(text, str):\n",
    "        # Removing patterns that contain years from the text ex. 2022/2023 so that our regex doesn't recognize it as a part of the fee\n",
    "        text = re.sub(r\"\\b\\d{4}/\\d{4}\\b|\\b\\d{4}/\\d{2}\\b\", \"\", text)\n",
    "\n",
    "        # Regular expression pattern for currency values\n",
    "        currency_pattern = r\"((eur|sek|chf|gbp|rmb|jpy|qr|[£€])\\s?\\d+(?:[.,\\s]\\d{3})*(?:[.,]\\d{2})?|\\d+(?:[.,\\s]\\d{3})*(?:[.,]\\d{2})?\\s?(eur|sek|chf|gbp|rmb|jpy|qr|[£€]))\"\n",
    "        matches = re.findall(currency_pattern, text)\n",
    "\n",
    "        # Exchange rates\n",
    "        exchange_rates = {\n",
    "            \"SEK\": 0.08588,\n",
    "            \"GBP\": 1.1443,\n",
    "            \"CHF\": 1.03708,\n",
    "            \"JPY\": 0.00618,\n",
    "            \"QR\": 0.25672,\n",
    "            \"RMB\": 0.12892,\n",
    "        }\n",
    "\n",
    "        # Converting to euros and calculating values\n",
    "        numeric_values = []\n",
    "        for value in matches:\n",
    "            value_numeric = convert_to_numeric(value[0])\n",
    "            currency = value[1].upper() \n",
    "            numeric_values.append(value_numeric * exchange_rates.get(currency, 1)) #converting all the fees to euros\n",
    "\n",
    "        # Returning the maximum value or None if no values\n",
    "        return max(numeric_values) if numeric_values else None\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>facultyName</th>\n",
       "      <th>isItFullTime</th>\n",
       "      <th>description</th>\n",
       "      <th>startDate</th>\n",
       "      <th>fees (euro)</th>\n",
       "      <th>modality</th>\n",
       "      <th>duration</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>administration</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comput scienc msc</td>\n",
       "      <td>univers hertfordshir</td>\n",
       "      <td>school physic engin comput scienc</td>\n",
       "      <td>full time</td>\n",
       "      <td>choos hert industri accredit accredit british ...</td>\n",
       "      <td>see cours</td>\n",
       "      <td>16500.0</td>\n",
       "      <td>msc</td>\n",
       "      <td>1 year full-tim 15 month full-tim 3 year part-tim</td>\n",
       "      <td>hatfield</td>\n",
       "      <td>unit kingdom</td>\n",
       "      <td>campu</td>\n",
       "      <td>http //www.findamasters.com/masters-degrees/co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>clinic cognit neurosci msc</td>\n",
       "      <td>sheffield hallam univers</td>\n",
       "      <td>postgradu cours</td>\n",
       "      <td>full time</td>\n",
       "      <td>develop broad rang practic skill essenti work ...</td>\n",
       "      <td>septemb</td>\n",
       "      <td>10310.0</td>\n",
       "      <td>msc</td>\n",
       "      <td>1 year full-tim 2 year part-tim</td>\n",
       "      <td>sheffield</td>\n",
       "      <td>unit kingdom</td>\n",
       "      <td>campu</td>\n",
       "      <td>http //www.findamasters.com/masters-degrees/co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>fashion forecast data analysi ma/msc</td>\n",
       "      <td>univers creativ art</td>\n",
       "      <td>busi school creativ industri</td>\n",
       "      <td>full time</td>\n",
       "      <td>uca 's new msc degre fashion forecast data ana...</td>\n",
       "      <td>septemb</td>\n",
       "      <td>10500.0</td>\n",
       "      <td>msc</td>\n",
       "      <td>1 year full time</td>\n",
       "      <td>farnham</td>\n",
       "      <td>unit kingdom</td>\n",
       "      <td>campu</td>\n",
       "      <td>http //www.findamasters.com/masters-degrees/co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>facad engin msc</td>\n",
       "      <td>univers west england bristol</td>\n",
       "      <td>depart architectur built environ</td>\n",
       "      <td>full time</td>\n",
       "      <td>façad engin disciplin right large-scal commerc...</td>\n",
       "      <td>septemb</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>msc</td>\n",
       "      <td>1 year full time 2 year part time</td>\n",
       "      <td>bristol</td>\n",
       "      <td>unit kingdom</td>\n",
       "      <td>campu</td>\n",
       "      <td>http //www.findamasters.com/masters-degrees/co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>fashion tech special master</td>\n",
       "      <td>poli.design società consortil responsabilità l...</td>\n",
       "      <td>postgradu cours</td>\n",
       "      <td>full time</td>\n",
       "      <td>fashion tech design decis role fashion lifesty...</td>\n",
       "      <td>april</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>msc</td>\n",
       "      <td>13 month</td>\n",
       "      <td>milan</td>\n",
       "      <td>itali</td>\n",
       "      <td>campu</td>\n",
       "      <td>http //www.findamasters.com/masters-degrees/co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              courseName  \\\n",
       "0                      comput scienc msc   \n",
       "29            clinic cognit neurosci msc   \n",
       "49  fashion forecast data analysi ma/msc   \n",
       "50                       facad engin msc   \n",
       "51           fashion tech special master   \n",
       "\n",
       "                                       universityName  \\\n",
       "0                                univers hertfordshir   \n",
       "29                           sheffield hallam univers   \n",
       "49                                univers creativ art   \n",
       "50                       univers west england bristol   \n",
       "51  poli.design società consortil responsabilità l...   \n",
       "\n",
       "                          facultyName isItFullTime  \\\n",
       "0   school physic engin comput scienc    full time   \n",
       "29                    postgradu cours    full time   \n",
       "49       busi school creativ industri    full time   \n",
       "50   depart architectur built environ    full time   \n",
       "51                    postgradu cours    full time   \n",
       "\n",
       "                                          description  startDate  fees (euro)  \\\n",
       "0   choos hert industri accredit accredit british ...  see cours      16500.0   \n",
       "29  develop broad rang practic skill essenti work ...    septemb      10310.0   \n",
       "49  uca 's new msc degre fashion forecast data ana...    septemb      10500.0   \n",
       "50  façad engin disciplin right large-scal commerc...    septemb      11500.0   \n",
       "51  fashion tech design decis role fashion lifesty...      april      11000.0   \n",
       "\n",
       "   modality                                           duration       city  \\\n",
       "0       msc  1 year full-tim 15 month full-tim 3 year part-tim   hatfield   \n",
       "29      msc                    1 year full-tim 2 year part-tim  sheffield   \n",
       "49      msc                                   1 year full time    farnham   \n",
       "50      msc                  1 year full time 2 year part time    bristol   \n",
       "51      msc                                           13 month      milan   \n",
       "\n",
       "         country administration  \\\n",
       "0   unit kingdom          campu   \n",
       "29  unit kingdom          campu   \n",
       "49  unit kingdom          campu   \n",
       "50  unit kingdom          campu   \n",
       "51         itali          campu   \n",
       "\n",
       "                                                  url  \n",
       "0   http //www.findamasters.com/masters-degrees/co...  \n",
       "29  http //www.findamasters.com/masters-degrees/co...  \n",
       "49  http //www.findamasters.com/masters-degrees/co...  \n",
       "50  http //www.findamasters.com/masters-degrees/co...  \n",
       "51  http //www.findamasters.com/masters-degrees/co...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying the function to the dataframe\n",
    "df_preprocessed[\"fees\"] = df_preprocessed[\"fees\"].apply(find_fees)\n",
    "df_preprocessed.rename(columns={\"fees\": \"fees (euro)\"}, inplace=True)\n",
    "df_preprocessed[df_preprocessed[\"fees (euro)\"].notna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Conjunctive query\n",
    "For the first version of the search engine, we narrowed our interest to the __description__ of each course. It means that you will evaluate queries only concerning the course's description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Vocabulary**\n",
    "Create a file named `vocabulary`, in the format you prefer, that maps each word to an integer (`term_id`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting all the words and giving them an unique id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary_df(df):\n",
    "    all_words = [\n",
    "        word\n",
    "        for description in df[\"description\"]\n",
    "        if isinstance(description, str)\n",
    "        for word in description.split()\n",
    "    ]\n",
    "\n",
    "    word_counts = Counter(all_words)\n",
    "\n",
    "    # Assign a unique ID to each word\n",
    "    vocabulary = {\n",
    "        word: idx for idx, (word, count) in enumerate(word_counts.items(), start=1)\n",
    "    }\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vocabulary_df(df_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the first brick of your homework is to create the Inverted Index. It will be a dictionary in this format:\n",
    "\n",
    "```\n",
    "{\n",
    "term_id_1:[document_1, document_2, document_4],\n",
    "term_id_2:[document_1, document_3, document_5, document_6],\n",
    "...}\n",
    "```\n",
    "where _document\\_i_ is the *id* of a document that contains that specific word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index_vocabulary(df, vocabulary):\n",
    "    inverted_index = {vocabulary[word]: [] for word in vocabulary}\n",
    "\n",
    "    # Populating the inverted index, processing only string descriptions\n",
    "    for doc_id, description in enumerate(df[\"description\"], start=1):\n",
    "        if isinstance(description, str):\n",
    "            words = set(description.split())  # to avoid duplicate entries\n",
    "            for word in words:\n",
    "                if word in vocabulary:\n",
    "                    inverted_index[vocabulary[word]].append(doc_id)\n",
    "\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = inverted_index_vocabulary(df_preprocessed, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing vocabulary and inverted_index for easier loading later on\n",
    "with open(\"vocabulary.json\", \"w\") as vocab_file:\n",
    "    json.dump(vocabulary, vocab_file)\n",
    "\n",
    "with open(\"inverted_index.json\", \"w\") as index_file:\n",
    "    json.dump(inverted_index, index_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2) Execute the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading files\n",
    "with open(\"vocabulary.json\", \"r\") as vocab_file:\n",
    "    vocabulary = json.load(vocab_file)\n",
    "\n",
    "with open(\"inverted_index.json\", \"r\") as index_file:\n",
    "    inverted_index = json.load(index_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting ids of the words in the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    query_terms = query.split()\n",
    "    query_term_ids = [\n",
    "        vocabulary.get(term) for term in query_terms if term in vocabulary\n",
    "    ]\n",
    "    return query_term_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these ids to find all the documents containing all the words in the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query_term_ids):\n",
    "    # Retrieve document lists for each term in the query\n",
    "    document_lists = [\n",
    "        inverted_index.get(str(term_id), []) for term_id in query_term_ids\n",
    "    ]\n",
    "\n",
    "    # Find the intersection of these lists\n",
    "    if document_lists:\n",
    "        common_documents = set(document_lists[0]).intersection(*document_lists[1:])\n",
    "        return sorted(common_documents)\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_execution(query):\n",
    "    query_preprocess = stem(punct(stopless(query)))\n",
    "\n",
    "    # Processing the query\n",
    "    query_term_ids = process_query(query_preprocess)\n",
    "    # Searching for documents\n",
    "    matching_doc_ids = search_documents(query_term_ids)\n",
    "    # Retrieving and displaying information\n",
    "    if matching_doc_ids:\n",
    "        return df.loc[list(matching_doc_ids), ['courseName', 'universityName', 'description', 'url']]\n",
    "    else:\n",
    "        print(\"No matching documents found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Computer Science (Data Science) - MSc</td>\n",
       "      <td>Trinity College Dublin</td>\n",
       "      <td>The MSc in Computer Science is an exciting one...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>MSc in Healthcare Leadership</td>\n",
       "      <td>University of Hull</td>\n",
       "      <td>Start date: January 2024Study healthcare leade...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>Marketing - MSc</td>\n",
       "      <td>Cardiff University</td>\n",
       "      <td>Why study this courseBring your interests and ...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>Cybercrime, Terrorism and Security</td>\n",
       "      <td>University of Portsmouth</td>\n",
       "      <td>This course is still being set up. For more in...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>Cybercrime and Digital Investigation MSc</td>\n",
       "      <td>Middlesex University</td>\n",
       "      <td>As our lives become increasingly digitised the...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>Cyberphysical Systems 2 year MSc</td>\n",
       "      <td>University of Nottingham</td>\n",
       "      <td>Cyber physical systems integrate computation w...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>Advanced Computer Science with Data Science</td>\n",
       "      <td>University of Strathclyde</td>\n",
       "      <td>Our MSc Advanced Computer Science with Data Sc...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>Advanced Computing - MSc</td>\n",
       "      <td>Imperial College London</td>\n",
       "      <td>This course is aimed at students who have a su...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>MSc Criminology and Criminal Psychology</td>\n",
       "      <td>University of Essex Online</td>\n",
       "      <td>Start Date: September, OctoberDevelop your ski...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>MSc Data Science</td>\n",
       "      <td>University of Essex Online</td>\n",
       "      <td>Start Date: OctoberUse the power of data to ma...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       courseName              universityName  \\\n",
       "2           Computer Science (Data Science) - MSc      Trinity College Dublin   \n",
       "633                  MSc in Healthcare Leadership          University of Hull   \n",
       "714                               Marketing - MSc          Cardiff University   \n",
       "723            Cybercrime, Terrorism and Security    University of Portsmouth   \n",
       "730      Cybercrime and Digital Investigation MSc        Middlesex University   \n",
       "732              Cyberphysical Systems 2 year MSc    University of Nottingham   \n",
       "1056  Advanced Computer Science with Data Science   University of Strathclyde   \n",
       "1058                     Advanced Computing - MSc     Imperial College London   \n",
       "1099      MSc Criminology and Criminal Psychology  University of Essex Online   \n",
       "1104                             MSc Data Science  University of Essex Online   \n",
       "\n",
       "                                            description  \\\n",
       "2     The MSc in Computer Science is an exciting one...   \n",
       "633   Start date: January 2024Study healthcare leade...   \n",
       "714   Why study this courseBring your interests and ...   \n",
       "723   This course is still being set up. For more in...   \n",
       "730   As our lives become increasingly digitised the...   \n",
       "732   Cyber physical systems integrate computation w...   \n",
       "1056  Our MSc Advanced Computer Science with Data Sc...   \n",
       "1058  This course is aimed at students who have a su...   \n",
       "1099  Start Date: September, OctoberDevelop your ski...   \n",
       "1104  Start Date: OctoberUse the power of data to ma...   \n",
       "\n",
       "                                                    url  \n",
       "2     https://www.findamasters.com/masters-degrees/c...  \n",
       "633   https://www.findamasters.com/masters-degrees/c...  \n",
       "714   https://www.findamasters.com/masters-degrees/c...  \n",
       "723   https://www.findamasters.com/masters-degrees/c...  \n",
       "730   https://www.findamasters.com/masters-degrees/c...  \n",
       "732   https://www.findamasters.com/masters-degrees/c...  \n",
       "1056  https://www.findamasters.com/masters-degrees/c...  \n",
       "1058  https://www.findamasters.com/masters-degrees/c...  \n",
       "1099  https://www.findamasters.com/masters-degrees/c...  \n",
       "1104  https://www.findamasters.com/masters-degrees/c...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"cyber security\"\n",
    "matching_doc_df = query_execution(query)\n",
    "matching_doc_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Conjunctive query & Ranking score\n",
    "\n",
    "For the second search engine, given a query, we want to get the *top-k* (the choice of *k* it's up to you!) documents related to the query. In particular:\n",
    "\n",
    "* Find all the documents that contain all the words in the query.\n",
    "* Sort them by their similarity with the query.\n",
    "* Return in output *k* documents, or all the documents with non-zero similarity with the query when the results are less than _k_. You __must__ use a heap data structure (you can use Python libraries) for maintaining the *top-k* documents.\n",
    "\n",
    "To solve this task, you must use the *tfIdf* score and the _Cosine similarity_. The field to consider is still the `description`. Let's see how.\n",
    "\n",
    "\n",
    "#### 2.2.1) Inverted index\n",
    "Your second Inverted Index must be of this format:\n",
    "\n",
    "```\n",
    "{\n",
    "term_id_1:[(document1, tfIdf_{term,document1}), (document2, tfIdf_{term,document2}), (document4, tfIdf_{term,document4}), ...],\n",
    "term_id_2:[(document1, tfIdf_{term,document1}), (document3, tfIdf_{term,document3}), (document5, tfIdf_{term,document5}), (document6, tfIdf_{term,document6}), ...],\n",
    "...}\n",
    "```\n",
    "\n",
    "Practically, for each word, you want the list of documents in which it is contained and the relative *tfIdf* score.\n",
    "\n",
    "__Tip__: *TfIdf* values are invariant for the query. Due to this reason, you can precalculate and store them accordingly.\n",
    "\n",
    "#### 2.2.2) Execute the query\n",
    "\n",
    "In this new setting, given a query, you get the proper documents (i.e., those containing all the query's words) and sort them according to their similarity to the query. For this purpose, as the scoring function, we will use the Cosine Similarity concerning the *tfIdf* representations of the documents.\n",
    "\n",
    "Given a query input by the user, for example:\n",
    "```\n",
    "advanced knowledge\n",
    "```\n",
    "The search engine is supposed to return a list of documents, __ranked__ by their Cosine Similarity to the query entered in the input.\n",
    "\n",
    "More precisely, the output must contain:\n",
    "* `courseName`\n",
    "* `universityName`\n",
    "* `description`\n",
    "* `URL`\n",
    "* The similarity score of the documents with respect to the query (float value between 0 and 1)\n",
    "  \n",
    "__Example Output__ for ```advanced knowledge```:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"img/output2.png\" width = 1000>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "df_preprocessed['description'].fillna(\"\", inplace=True)\n",
    "tfidf_matrix = vectorizer.fit_transform(df_preprocessed['description'])\n",
    "feature_index = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 10332)\n",
      "250334\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix.shape)  # This prints the dimensions of the matrix\n",
    "print(tfidf_matrix.count_nonzero())  # This prints the number of non-zero entries in the matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inverted_index_tfidf(df, vocabulary):\n",
    "    inverted_index = {vocabulary[word]: [] for word in vocabulary}\n",
    "    for doc_id, description in enumerate(df['description'], start=1):\n",
    "        if isinstance(description, str):\n",
    "            words = set(description.split())\n",
    "            for word in words:\n",
    "                if word in vocabulary:\n",
    "                    term_id = vocabulary[word]\n",
    "                    idx = feature_index.get(word)\n",
    "                    if idx is not None:\n",
    "                        score = tfidf_matrix[doc_id - 1, idx] \n",
    "                        inverted_index[term_id].append((doc_id, score))\n",
    "\n",
    "    return inverted_index\n",
    "\n",
    "inverted_index_tfidf = create_inverted_index_tfidf(df_preprocessed, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tfidf_inverted_index.json\", \"w\") as index_file:\n",
    "    json.dump(inverted_index, index_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term ID: 1, Postings List: [(1, 0.0877462699718074), (45, 0.11712786492027691), (53, 0.06736352759705212), (88, 0.10474995073485001), (103, 0.11110796031378978), (135, 0.16984840797741835), (138, 0.11543974660709833), (170, 0.13577607583088047), (178, 0.12475318280833658), (194, 0.10151259207866951), (359, 0.08667479936917441), (368, 0.13649591129163866), (445, 0.10150179337929957), (449, 0.0934016107339302), (496, 0.15660031059364365), (497, 0.10791850730824007), (515, 0.0770491664463767), (533, 0.10585424489673981), (539, 0.13471618825133916), (559, 0.09277924544757649), (579, 0.10736507632299537), (584, 0.03361201818742781), (644, 0.09468598313071894), (666, 0.08541041701682388), (677, 0.1041745850658261), (691, 0.09076263666699377), (695, 0.15132232896124062), (730, 0.09251485250457361), (735, 0.13749833851757262), (772, 0.11335085606483787), (778, 0.1221525852746661), (826, 0.0630219788376543), (855, 0.09976791569550218), (885, 0.10629745899268139), (940, 0.08662779356494463), (957, 0.11457213765135249), (979, 0.1146061386416074), (992, 0.085139376485034), (1010, 0.09439363778890482), (1052, 0.1172988553187549), (1056, 0.11098836677109214), (1091, 0.0662358971862704), (1140, 0.07631827333068521), (1141, 0.10479125429180883), (1144, 0.09821886051491026), (1147, 0.08507960730379527), (1150, 0.13922365392705585), (1173, 0.08834844967080742), (1177, 0.09880822159905968), (1247, 0.13760075785182688), (1249, 0.12726257779596536), (1258, 0.10546056616590486), (1313, 0.12708514326054723), (1340, 0.08662779356494463), (1347, 0.08662779356494463), (1372, 0.06939844408096525), (1404, 0.09329208080638828), (1428, 0.12807758300527486), (1458, 0.10453499515593416), (1477, 0.09882090923700283), (1536, 0.12628058930148972), (1537, 0.139211174967308), (1538, 0.11551651713097064), (1544, 0.139211174967308), (1605, 0.09879747392215174), (1612, 0.12334309412966923), (1627, 0.11842729293301475), (1644, 0.08971326433932983), (1648, 0.10555291044061192), (1663, 0.10418489271754408), (1668, 0.09001569766122526), (1683, 0.11707083208627571), (1686, 0.09806356069420921), (1705, 0.07970051049501146), (1724, 0.19139307655868432), (1731, 0.06643388332209864), (1816, 0.0812048185535491), (1829, 0.10769840551244672), (1852, 0.11060309917673018), (1853, 0.08962396735577897), (1965, 0.30389706926091975), (1987, 0.11700408658735073), (2013, 0.09685476807992706), (2025, 0.1153502474681442), (2031, 0.13443050415769864), (2038, 0.12469451591240908), (2059, 0.12871984542795242), (2062, 0.10997285303816662), (2063, 0.10146973186495326), (2070, 0.10057476542039333), (2093, 0.11546000492241117), (2096, 0.28118926204853223), (2183, 0.07776716743377941), (2186, 0.09288204895423793), (2198, 0.11494774004643006), (2225, 0.08384729354267074), (2229, 0.09606392517325874), (2292, 0.22310788211614874), (2297, 0.14000848707284377), (2303, 0.06610122359509062), (2307, 0.13297984003830124), (2312, 0.12305168450773565), (2313, 0.12442427538924289), (2342, 0.09837922968235817), (2398, 0.07473949529894883), (2432, 0.10754575716064661), (2448, 0.11123838366806059), (2476, 0.20314037801407045), (2509, 0.11264851181606038), (2540, 0.11474447825854577), (2564, 0.08906932317994444), (2578, 0.08962086462931586), (2584, 0.12343373252396567), (2589, 0.10091025285316421), (2596, 0.23103746651406334), (2605, 0.08662779356494463), (2639, 0.11214285740892353), (2649, 0.12043679203720936), (2673, 0.15951399014949813), (2677, 0.08037402754534614), (2682, 0.08206229113588878), (2714, 0.09864440191764158), (2741, 0.14097770387841235), (2848, 0.09731016747820595), (2943, 0.10527356282837234), (2979, 0.13110678962408506), (3052, 0.11005666548805634), (3069, 0.07744280443617482), (3107, 0.13607035583810986), (3129, 0.12014548102972722), (3136, 0.11321162008934806), (3168, 0.12459868820289845), (3169, 0.13495447064232022), (3180, 0.14033359788646863), (3247, 0.08905649030030278), (3253, 0.12765053364133627), (3283, 0.10546638216410284), (3286, 0.09084203834065856), (3295, 0.11449924528355064), (3346, 0.10603390520286528), (3354, 0.10167373125959085), (3358, 0.1080863562945368), (3393, 0.09162382083467717), (3399, 0.09356834254553849), (3424, 0.1232988883133375), (3431, 0.07809653693874524), (3464, 0.08423649940693706), (3484, 0.09775515563964886), (3485, 0.08012415516258813), (3497, 0.25002065376536803), (3508, 0.12864696242314372), (3521, 0.1029841098778101), (3524, 0.11079234544858621), (3526, 0.11840731803791993), (3543, 0.16854233432542623), (3597, 0.11960838956164), (3606, 0.11155119741959639), (3651, 0.17841445058117447), (3672, 0.08935644327840568), (3673, 0.08935644327840568), (3675, 0.08935644327840568), (3681, 0.08008060328191627), (3739, 0.09608961433624504), (3759, 0.145375697401958), (3777, 0.18371978743520245), (3789, 0.1303471450598944), (3793, 0.09372515647745747), (3817, 0.08433312104809758), (3882, 0.13476214556850113), (3944, 0.06014778671429178), (3962, 0.0774502372589919), (4001, 0.10619192633013626), (4011, 0.08827534488262839), (4017, 0.0883293603889514), (4162, 0.10032791965561268), (4276, 0.08348804187343886), (4281, 0.09658882005261565), (4289, 0.12574066923193084), (4327, 0.08877431182116063), (4328, 0.11868268884398568), (4352, 0.09864625420954136), (4370, 0.11072214236344391), (4374, 0.08123291537725982), (4399, 0.12404759750722516), (4432, 0.09111507716179267), (4433, 0.10772195937408552), (4435, 0.10772195937408552), (4438, 0.1903742764093812), (4463, 0.07546474448031633), (4495, 0.11915077703741055), (4579, 0.13110925009773394), (4593, 0.0785222071736443), (4677, 0.09671812060038631), (4682, 0.10518389105291168), (4693, 0.11038678409965588), (4721, 0.1058260166619198), (4736, 0.09624410558233919), (4767, 0.22098085502406356), (4838, 0.09753982832744167), (4932, 0.11403043247545999), (4944, 0.09578715223869076), (4961, 0.13108698788040798), (4969, 0.09703471039608275), (4976, 0.10837662928747047), (4987, 0.09937696804749899), (5001, 0.12684945973613485), (5037, 0.08295311749841222), (5054, 0.10146066390357637), (5093, 0.07113609124417987), (5175, 0.13861266835361938), (5195, 0.10093451862772894), (5198, 0.07071509555231367), (5202, 0.1269875518640285), (5225, 0.10113158951065204), (5256, 0.10976718777472218), (5290, 0.28263228524515177), (5306, 0.12325123455612065), (5332, 0.0645075975833264), (5445, 0.10398029264686795), (5492, 0.08889370196225632), (5495, 0.18569327909521324), (5505, 0.11771732757028913), (5510, 0.10101522205216935), (5534, 0.09534028852473225), (5550, 0.12068634323998421), (5575, 0.12443580131359246), (5579, 0.12274777817415738), (5603, 0.17811398047534963), (5663, 0.054695309876829176), (5677, 0.07651013894724937), (5722, 0.10558786674551329), (5730, 0.08855459570915615), (5750, 0.1095307049629265), (5755, 0.1176128447874236), (5794, 0.1262853226317013), (5810, 0.2599530859448118), (5814, 0.10502664556190856), (5825, 0.15215254725337896), (5837, 0.10743762715908045), (5872, 0.10256906159242936), (5952, 0.11535589930725128), (5980, 0.0873361151447488), (5994, 0.0995767729307718)]\n",
      "Term ID: 2, Postings List: [(1, 0.12518888149172272), (138, 0.1646995679938742), (359, 0.12366019877577386), (730, 0.13199228765097912), (940, 0.12359313491018692), (1091, 0.09449971931586526), (1144, 0.14013027896460764), (1147, 0.12138431502033391), (1340, 0.12359313491018692), (1347, 0.12359313491018692), (1458, 0.14914160025854933), (1644, 0.12799522100734853), (1648, 0.15059387482227815), (1663, 0.14864210401006311), (1668, 0.12842670703297765), (1686, 0.1399087104482972), (2229, 0.13705580132362055), (2303, 0.094307578541657), (2312, 0.17555963067313582), (2605, 0.12359313491018692), (2677, 0.11467079583690185), (2848, 0.13883383337300723), (3052, 0.15701944775071627), (3346, 0.15128011705581382), (3354, 0.14505939338011503), (3358, 0.15420837892455627), (3393, 0.13072103978866112), (3399, 0.13349531723768904), (3485, 0.11431429926874917), (3681, 0.11425216316621258), (3739, 0.1370924524266446), (3793, 0.13371904595852882), (4011, 0.12594372037356116), (4017, 0.1260207850832287), (4463, 0.10766665017880374), (5037, 0.11835042104028223), (5093, 0.10149089755511317), (5332, 0.09203392909772079), (5492, 0.12682593942613152), (5495, 0.13246565305812513), (5677, 0.1091581296921213), (5730, 0.12634213159537017)]\n",
      "Term ID: 3, Postings List: [(1, 0.10915658586151192), (9, 0.09988515421649588), (29, 0.06332650419423898), (31, 0.061270882000241764), (32, 0.11206380628647686), (36, 0.11468376346076135), (42, 0.08774299788633427), (44, 0.08774299788633427), (48, 0.09521377147723538), (50, 0.23110420640102608), (51, 0.09748402270489838), (52, 0.04322363764278498), (55, 0.08912174290949622), (57, 0.07123266465720156), (59, 0.0939754790908695), (67, 0.11293534795741655), (73, 0.07988559562562175), (76, 0.1655805773139368), (81, 0.05461470821001292), (88, 0.1954638127931516), (89, 0.2161346182661218), (90, 0.062157784613841846), (113, 0.06028410515151762), (124, 0.06749786008935484), (129, 0.16407273933977928), (138, 0.07180367106429465), (151, 0.05792925287138022), (152, 0.16836665238858198), (153, 0.05947436570168241), (155, 0.05947436570168241), (160, 0.08625045298679328), (169, 0.0739075930532195), (179, 0.07655224517319584), (186, 0.06140361161067564), (188, 0.15491342176901376), (189, 0.10919187583251896), (191, 0.09868166753490604), (193, 0.12011736378232223), (194, 0.06314096301085015), (205, 0.12450216488984708), (215, 0.06638073219435303), (216, 0.07309595197112193), (226, 0.18517069765135427), (228, 0.18474571761344397), (229, 0.18492869722084276), (240, 0.060443490468468024), (255, 0.043201866110758706), (266, 0.16758482143990477), (276, 0.12710284688399534), (278, 0.05153931700839275), (288, 0.17706219319109215), (300, 0.09547096578186351), (309, 0.21404284257591946), (310, 0.08980336371022925), (311, 0.05758981625130345), (316, 0.09951451856523963), (319, 0.06646273748150934), (323, 0.0689075742500866), (335, 0.11035643595377072), (336, 0.08729604512099334), (343, 0.0812471721053732), (348, 0.06312121744966494), (356, 0.06428647848208348), (357, 0.10429439970722529), (365, 0.07682116209084666), (377, 0.05126122823859008), (379, 0.06174066018703309), (383, 0.19485457660707967), (384, 0.0737021022794255), (397, 0.07270174495996537), (398, 0.08474532692209136), (401, 0.05146161865932475), (406, 0.04355953604622776), (407, 0.07497365353024461), (408, 0.05854331813682833), (435, 0.06782147965757875), (436, 0.07089923790949705), (441, 0.05829814204381359), (443, 0.10568559990045263), (450, 0.13583846656037854), (451, 0.08503026001684463), (453, 0.06018992112861096), (461, 0.12717498730386467), (462, 0.08071205011687207), (464, 0.15532525920539358), (465, 0.126368790489065), (475, 0.13453094520978964), (476, 0.04627911407149059), (478, 0.13655681863129912), (508, 0.07460843722011523), (514, 0.29795400705257963), (515, 0.0958493615223084), (516, 0.06498012229934136), (517, 0.1250963931878373), (518, 0.0640532083455777), (519, 0.06646620614977268), (523, 0.16979126788226337), (542, 0.24802160942975807), (545, 0.06299838988369809), (546, 0.08235477160544404), (547, 0.06477375575661386), (550, 0.21693746056997634), (562, 0.05791884514437435), (563, 0.07714580083676931), (584, 0.010453359300724389), (586, 0.07415547432780287), (588, 0.14092377658170255), (590, 0.2455017700062242), (592, 0.06159529036304588), (595, 0.05668261043082551), (596, 0.1255074024163501), (598, 0.19395981384631866), (617, 0.0695386878608673), (619, 0.27635956810147194), (620, 0.13509256457361385), (623, 0.15241849923843173), (624, 0.13421989048660757), (629, 0.0633901532222613), (635, 0.06540667628667482), (643, 0.10217283937079413), (647, 0.07008307896713713), (649, 0.1496718137037796), (651, 0.06946632149211197), (653, 0.10052468289446248), (654, 0.12198558979505396), (661, 0.13077093547922433), (665, 0.06119205546707434), (668, 0.1521524644418302), (675, 0.07138990833215825), (679, 0.05029388419199285), (681, 0.07225738575493915), (685, 0.2103428010486723), (686, 0.2103428010486723), (687, 0.1187580115709847), (689, 0.08897466811187109), (698, 0.06265678015565829), (700, 0.0697538409963681), (706, 0.05500178745603637), (711, 0.2063557788569978), (716, 0.09278414924791005), (719, 0.1214584472680157), (720, 0.06269927889555411), (730, 0.17263307222276086), (731, 0.0574952166766244), (738, 0.13057227228793142), (742, 0.06546172842608787), (748, 0.06942966740297993), (749, 0.05914979869512138), (771, 0.06800042685230356), (783, 0.1717343849239957), (784, 0.07269491041376144), (792, 0.1306468560989319), (798, 0.10054473029047918), (803, 0.13566180254050145), (811, 0.2120839960075568), (814, 0.017828518383681356), (820, 0.06386912089549147), (827, 0.039844742319735095), (832, 0.058789441901213275), (836, 0.06416212713883769), (837, 0.06852216598299977), (851, 0.05794175594870657), (853, 0.07197324648558359), (856, 0.06649040600103834), (857, 0.15374028434247164), (861, 0.05839810679574131), (862, 0.061002730074155694), (866, 0.059644732256048515), (870, 0.18041882122426878), (872, 0.10941863566507308), (873, 0.06653642328783782), (874, 0.07577323911449353), (883, 0.14923923234282938), (885, 0.06611715639378858), (895, 0.11966762700471652), (901, 0.14290455592946916), (902, 0.06987936950036931), (903, 0.06897946066939717), (905, 0.07014492659498532), (906, 0.3376901163071158), (907, 0.06893529801335195), (908, 0.08295461197559363), (909, 0.07149633148299732), (917, 0.06305978163559595), (920, 0.06654252250850304), (921, 0.052195532328139574), (924, 0.09891025018248957), (927, 0.05465584192596994), (936, 0.06251933430553507), (940, 0.1077651983304064), (957, 0.07126401717642845), (958, 0.07183891191864601), (960, 0.10269546691351139), (961, 0.06364178944009415), (964, 0.07156421487031325), (965, 0.06816977730746772), (966, 0.08194673941541906), (967, 0.13649159466015212), (968, 0.0638534444297404), (969, 0.07803079080269039), (974, 0.06280952216492387), (975, 0.06850951092468012), (979, 0.07128516583615684), (993, 0.06790046596311027), (1017, 0.07670524673039446), (1020, 0.06650637260367916), (1024, 0.06026184417247117), (1027, 0.12164231258441632), (1030, 0.08963566526724506), (1036, 0.07032065954566004), (1037, 0.0936226416888395), (1038, 0.09294311432320355), (1043, 0.07578581676872752), (1047, 0.05583740127907791), (1054, 0.06437634313041919), (1057, 0.13754803936266846), (1059, 0.14670742356393238), (1062, 0.06275464704110598), (1063, 0.07760376658921718), (1065, 0.10714004520377349), (1083, 0.05909546045250894), (1094, 0.0801048200451794), (1097, 0.07003533620421547), (1103, 0.07135319226860844), (1128, 0.1166793355416365), (1130, 0.16132279827926244), (1133, 0.07492851022795348), (1135, 0.17910443801806317), (1136, 0.052066020725030686), (1137, 0.06965881332682798), (1138, 0.05610615856957479), (1140, 0.047470064301877925), (1144, 0.06109225773619987), (1147, 0.0529196253168615), (1149, 0.1276981137838364), (1150, 0.08659729204856742), (1165, 0.2628585236393986), (1170, 0.12615820532376726), (1180, 0.05731704016281246), (1181, 0.08385400986393297), (1182, 0.22364178267578913), (1185, 0.17437202464076487), (1214, 0.13888022958921145), (1234, 0.0707441397592305), (1241, 0.05850628778355385), (1242, 0.07088554329969596), (1243, 0.06498865211007035), (1247, 0.08558784859964953), (1253, 0.08743066216317784), (1258, 0.1311932159554011), (1277, 0.06500134199061514), (1279, 0.0948981501086729), (1280, 0.059962953293828204), (1284, 0.059962953293828204), (1285, 0.059962953293828204), (1289, 0.059962953293828204), (1307, 0.06748952934439617), (1320, 0.09480740544648629), (1330, 0.07656831044331912), (1340, 0.1077651983304064), (1347, 0.1077651983304064), (1355, 0.05615025283004265), (1359, 0.05262393221719535), (1367, 0.07475704802292936), (1373, 0.12177627817344504), (1374, 0.12367737658504457), (1380, 0.12732100873491392), (1381, 0.07456735421659139), (1383, 0.07708040267385721), (1389, 0.06854274269145814), (1392, 0.06042893932532323), (1394, 0.08240978264123097), (1399, 0.0425543035388349), (1404, 0.05802779441230686), (1408, 0.05679759449103285), (1411, 0.25215213431798716), (1415, 0.14099399916341612), (1419, 0.13258064997143906), (1421, 0.07111722585874374), (1422, 0.055460153444605004), (1426, 0.11061797402059216), (1428, 0.07966442158021134), (1429, 0.14516836339375241), (1430, 0.0800978689810619), (1431, 0.08688949862395302), (1432, 0.21693843008320446), (1437, 0.12129557421923587), (1440, 0.08688949862395302), (1458, 0.13004180323491443), (1464, 0.08803716507299267), (1480, 0.07634136533673373), (1481, 0.06670125536472851), (1490, 0.06829291894220808), (1493, 0.08716876970763526), (1495, 0.09305605961026114), (1499, 0.09545119046351568), (1503, 0.06189516697080807), (1505, 0.11784144341982482), (1506, 0.07180198122521712), (1508, 0.06566731311141068), (1509, 0.13970092943710272), (1510, 0.13618463687243487), (1513, 0.1770802308523064), (1514, 0.0710667674747968), (1525, 0.11803921154289862), (1526, 0.1323176686268163), (1533, 0.10216440619317459), (1541, 0.06640143631474381), (1546, 0.0838066518772476), (1550, 0.06897183105689127), (1555, 0.06297903135029509), (1575, 0.13675058274108814), (1598, 0.07180876306553748), (1606, 0.0589606832218648), (1621, 0.06283651048996292), (1636, 0.09104664970715644), (1644, 0.16740529788193217), (1646, 0.1415410877097862), (1647, 0.08425492956281261), (1648, 0.19696213870649515), (1650, 0.06707195869985227), (1651, 0.047614839128784496), (1657, 0.05519325743366454), (1659, 0.07142484340181293), (1661, 0.18386835136429547), (1663, 0.3240156872494109), (1672, 0.07819438242012992), (1694, 0.0547185935419519), (1696, 0.06315961694274219), (1701, 0.05020853843670877), (1718, 0.0722964229098574), (1720, 0.05396707034723522), (1731, 0.08264392197289151), (1742, 0.07638763758196342), (1747, 0.05625764387728198), (1755, 0.06938896442860086), (1761, 0.0840248833374793), (1765, 0.06761784037696217), (1772, 0.060866616114716464), (1787, 0.12231408039037538), (1789, 0.07823343477323022), (1791, 0.06662976114511576), (1792, 0.1040667086651671), (1800, 0.07187113832180911), (1806, 0.07031495039260938), (1807, 0.06423881840800523), (1808, 0.0656101941967586), (1812, 0.24067461399074178), (1815, 0.13625063064945708), (1830, 0.0787313751170126), (1835, 0.11274636175394223), (1836, 0.09638604788143289), (1842, 0.1800823286413117), (1848, 0.050394408353830134), (1850, 0.07317425395337253), (1853, 0.11149244624373994), (1855, 0.06464487212393047), (1859, 0.2052754388654275), (1865, 0.056824485365253224), (1872, 0.05893150073603015), (1874, 0.04656199746087149), (1881, 0.10306926967860233), (1887, 0.0981474021796558), (1890, 0.06791378235126619), (1897, 0.10484093141765934), (1909, 0.06848820716398443), (1922, 0.09492186287329962), (1923, 0.09492186287329962), (1924, 0.13979034424545791), (1925, 0.06231184444362776), (1926, 0.12161516697909376), (1928, 0.05076826832899392), (1929, 0.11854566998654954), (1930, 0.07131930513287887), (1931, 0.17556578233513212), (1932, 0.07170948297573408), (1934, 0.07578130777602603), (1936, 0.057858186548873314), (1939, 0.0561742081799056), (1941, 0.09093643595767888), (1944, 0.07291563436960884), (1949, 0.06230551215408363), (1951, 0.1644126870563417), (1960, 0.07688325271604239), (1962, 0.05759197743246481), (1972, 0.06598676273663673), (1975, 0.06720232503173827), (1977, 0.07971166727020865), (1981, 0.11041006138261382), (1982, 0.06969811696628052), (2007, 0.049981118209256464), (2028, 0.07410899142521542), (2030, 0.06215769918864529), (2036, 0.062403403775893984), (2039, 0.04250966657644236), (2042, 0.07155009407654132), (2043, 0.18613971661749282), (2044, 0.055678616501381), (2046, 0.06814118388565174), (2047, 0.18591537495857222), (2048, 0.051538173881138474), (2050, 0.05959796510612785), (2069, 0.07289431099086684), (2077, 0.0699791490767949), (2079, 0.10582833923351942), (2083, 0.13140976807116658), (2084, 0.09095404859185112), (2085, 0.07122996074064113), (2092, 0.03969723766310081), (2105, 0.06856643869484383), (2109, 0.06315472980276925), (2115, 0.057311209506167075), (2117, 0.057988525440329876), (2118, 0.06486804493119622), (2119, 0.0706830157184673), (2122, 0.05942968091151578), (2125, 0.09494812718209529), (2129, 0.1268814515000329), (2132, 0.060397773010767965), (2133, 0.07020301500102238), (2135, 0.06773230716594476), (2138, 0.06142341116593058), (2139, 0.050777053297140766), (2142, 0.06274363188799337), (2143, 0.06768982929820255), (2150, 0.07657078639680132), (2152, 0.11096154657352356), (2153, 0.10230652172102994), (2157, 0.08681766021887917), (2158, 0.06122295384516676), (2159, 0.09172178568159231), (2160, 0.09053434244915752), (2168, 0.05798262536653596), (2176, 0.05664867968116284), (2184, 0.08532227350804447), (2186, 0.11554550814437987), (2188, 0.07403624597702231), (2194, 0.14658753325563764), (2200, 0.05844587661907118), (2214, 0.15189573361654768), (2215, 0.06640572959321753), (2216, 0.07403872409120663), (2217, 0.07260658234600618), (2218, 0.10830946346475594), (2220, 0.07971556389414847), (2221, 0.05984945370881655), (2225, 0.10430624914069395), (2228, 0.13025837989258604), (2233, 0.04971029711372539), (2262, 0.0826390684172414), (2267, 0.16104931949014958), (2268, 0.10729732415498008), (2269, 0.10729732415498008), (2273, 0.066716578298801), (2274, 0.06703220112735014), (2275, 0.08081295604702829), (2276, 0.13159519206829934), (2279, 0.06722851498638696), (2280, 0.19220026433057313), (2287, 0.15579128046255197), (2289, 0.06350340329215366), (2294, 0.06490726734689915), (2303, 0.08223009241562959), (2305, 0.10031494002999122), (2308, 0.08377577534695134), (2313, 0.23217617861384984), (2314, 0.06125309228363289), (2315, 0.17509706312734305), (2316, 0.04958715273503907), (2317, 0.04902742385090867), (2318, 0.10499350326342285), (2319, 0.0633517401140253), (2320, 0.11748261783763321), (2325, 0.05537495135296599), (2326, 0.05196355488762177), (2332, 0.13365001283960168), (2336, 0.1264586544075957), (2337, 0.13964185767972723), (2362, 0.11689397875374322), (2371, 0.34653869239480434), (2372, 0.11231516149660897), (2374, 0.09002230205294948), (2375, 0.06298518702384784), (2377, 0.07863890035828572), (2380, 0.05893648263762491), (2381, 0.06916461423902787), (2382, 0.05778607550222982), (2385, 0.24011248042275168), (2393, 0.06972498889139309), (2395, 0.0611961645577477), (2396, 0.11350291178651753), (2402, 0.06569834894934683), (2412, 0.08849715655278538), (2413, 0.11534289468302958), (2434, 0.10239721770066369), (2450, 0.06824722035359103), (2464, 0.15179595924723502), (2472, 0.07747633789660563), (2475, 0.09185842696708527), (2477, 0.04546484625016773), (2478, 0.07312037965943254), (2489, 0.12199372315454464), (2506, 0.06214722239821655), (2508, 0.11244491455294056), (2510, 0.06821990586270733), (2512, 0.06426671405806796), (2514, 0.07650985918519077), (2517, 0.05213269685248646), (2518, 0.07244323509170303), (2521, 0.06158086183275728), (2523, 0.0739776331861368), (2524, 0.0748509557470862), (2525, 0.06840507400189821), (2526, 0.07317760767004591), (2527, 0.15355579462234373), (2528, 0.1642965432865378), (2529, 0.08051719806435531), (2530, 0.2796855543860832), (2531, 0.0870043525256662), (2532, 0.12817585524426167), (2533, 0.17096741415285385), (2534, 0.3620631253642735), (2535, 0.07487826153567703), (2545, 0.06335398816656666), (2551, 0.0786440356918516), (2553, 0.06784758316217632), (2554, 0.17459544950390157), (2555, 0.07305939242772395), (2556, 0.16782201114981246), (2561, 0.08018708851892353), (2563, 0.056045929339706695), (2567, 0.05546501596796898), (2568, 0.06613810855769768), (2569, 0.24778177085215736), (2575, 0.12849308317892946), (2577, 0.1537867369405322), (2581, 0.0912607667277498), (2583, 0.07766075856982443), (2584, 0.07677594060002882), (2599, 0.15695477866073293), (2601, 0.09067308971856783), (2605, 0.1077651983304064), (2611, 0.07267059675621838), (2613, 0.06406894238298784), (2619, 0.05865615511062572), (2622, 0.09591611246836813), (2641, 0.06626594529651701), (2644, 0.2465474199126588), (2653, 0.0594555676552416), (2656, 0.050445993781788344), (2658, 0.05427001263438055), (2659, 0.24171662535812782), (2660, 0.057858284023454484), (2661, 0.06648361666639133), (2662, 0.04538701046844707), (2666, 0.14771981525537928), (2667, 0.05063494714167934), (2668, 0.11343524673704425), (2669, 0.0886732146589244), (2672, 0.0690544779345738), (2677, 0.14997824594039072), (2680, 0.07896056835144946), (2683, 0.07550512928061551), (2689, 0.08575780140727968), (2718, 0.1750070987418507), (2724, 0.06108159485636606), (2727, 0.07551911842259569), (2735, 0.10047360541106642), (2738, 0.10464902069921135), (2739, 0.07249947451601899), (2747, 0.14272830883324727), (2756, 0.05417305093124656), (2757, 0.1998613462608367), (2760, 0.056892491139557196), (2764, 0.08459408202904346), (2769, 0.059399089422834825), (2772, 0.08467666688778952), (2784, 0.05680953158383173), (2786, 0.04462363299802982), (2788, 0.0744940531198936), (2792, 0.04383707879393229), (2793, 0.04130434194520596), (2798, 0.0757114079984447), (2801, 0.0477235766985345), (2803, 0.10223097694038265), (2819, 0.07125219253972531), (2826, 0.08879718364893967), (2840, 0.06229541379918143), (2846, 0.0557314894440899), (2855, 0.06622001896473226), (2868, 0.13450706782488683), (2870, 0.06469778909755672), (2871, 0.07619353086021008), (2879, 0.11295818686858522), (2881, 0.07055793548620753), (2883, 0.06903162480391073), (2885, 0.20230352286625614), (2886, 0.06582456920604389), (2887, 0.12328441363398471), (2890, 0.06562897079238565), (2893, 0.07560083006021483), (2894, 0.06292150172349753), (2899, 0.06111023321963736), (2910, 0.08350380392406893), (2927, 0.07325986511544844), (2929, 0.09555939125752425), (2930, 0.07903750038987048), (2940, 0.16068853423353555), (2945, 0.08727745312931803), (2952, 0.08781408749779593), (2960, 0.09000638564653284), (2964, 0.07966042207737972), (2968, 0.07514812175009444), (2970, 0.1680391616664077), (2995, 0.10101577666160634), (3004, 0.08904208490726113), (3005, 0.13376445512480425), (3006, 0.1563375566469457), (3007, 0.1310608973975649), (3008, 0.1361569996458642), (3013, 0.14604862996560067), (3020, 0.10079249780015215), (3023, 0.050227994735473486), (3028, 0.06187841790024641), (3030, 0.0707793169039527), (3031, 0.13735292965883525), (3032, 0.07568032631156785), (3034, 0.04763832827591038), (3035, 0.06279661363566613), (3038, 0.14727284977914598), (3045, 0.06279661363566613), (3050, 0.0997597163788429), (3052, 0.13691077535077661), (3054, 0.0758760485865393), (3055, 0.08863120343337436), (3058, 0.07949204977569135), (3066, 0.06717449351937738), (3068, 0.05269351271775424), (3069, 0.048169524097774426), (3070, 0.20658729047200597), (3071, 0.05857436641364046), (3106, 0.061084339339340495), (3122, 0.29606900527401864), (3143, 0.10024350123713771), (3159, 0.14318391394815286), (3186, 0.1328195252984419), (3192, 0.06447974653183577), (3230, 0.0779596534339729), (3232, 0.0779596534339729), (3237, 0.0779596534339729), (3238, 0.0779596534339729), (3253, 0.07939879632584528), (3255, 0.20435579081309344), (3259, 0.08842315818647485), (3260, 0.08522460565003391), (3261, 0.0822911737774234), (3282, 0.06452746229561772), (3283, 0.0656002255360701), (3290, 0.07478752694148437), (3304, 0.06046643992690842), (3305, 0.07414871283038892), (3310, 0.06889181129432458), (3311, 0.059034998487748826), (3315, 0.050676209560778396), (3318, 0.08367949510788639), (3321, 0.05498937688161698), (3324, 0.06306258661987657), (3327, 0.0621978378855208), (3328, 0.09253318770251337), (3336, 0.049659370707968525), (3341, 0.12230830631453185), (3343, 0.08496739244915145), (3345, 0.1271115024496969), (3348, 0.04694309232613816), (3367, 0.07458689223349145), (3377, 0.06534409756444776), (3391, 0.2469383222038351), (3392, 0.11418957383185184), (3393, 0.056990134561353), (3394, 0.11513058934663109), (3395, 0.05642118850394771), (3396, 0.07463457644590105), (3397, 0.07609784186346517), (3400, 0.05410988910107036), (3401, 0.24961464479668766), (3402, 0.11418957383185184), (3403, 0.11418957383185184), (3405, 0.18254400029283332), (3407, 0.07327186015950898), (3410, 0.0833743898791697), (3414, 0.1490034323166502), (3420, 0.08477456656014966), (3422, 0.07039311205003881), (3425, 0.08479383877166213), (3428, 0.0747638916847498), (3439, 0.06818974249330335), (3445, 0.08170722982946585), (3451, 0.1700112559377464), (3455, 0.12743156637110212), (3470, 0.08669664382614681), (3474, 0.06601863124423502), (3475, 0.04374651908112309), (3481, 0.16996379892529276), (3483, 0.08464446205827335), (3484, 0.1216076654131649), (3485, 0.0996746554058223), (3486, 0.17962331359162795), (3487, 0.06754075252636743), (3489, 0.15965303198583866), (3490, 0.13174706134057165), (3491, 0.08870819623030826), (3493, 0.07041654510549693), (3494, 0.15074543392171705), (3495, 0.1601183008138687), (3496, 0.07795612864399618), (3498, 0.07501211006570717), (3502, 0.12747339388414747), (3503, 0.06906864312355764), (3505, 0.0773827702489739), (3507, 0.09478306469519891), (3509, 0.13750869486893236), (3510, 0.13708510891757242), (3516, 0.09233950800115157), (3519, 0.07483076500724517), (3540, 0.0653314010690972), (3541, 0.09863518117531421), (3547, 0.15266463324505994), (3550, 0.08255104948156432), (3553, 0.048557239799151816), (3559, 0.07115256138750059), (3566, 0.2207041626997957), (3568, 0.14480208678525064), (3572, 0.030261601389956), (3580, 0.06782293750529413), (3588, 0.12599276747665017), (3595, 0.16561412142950635), (3604, 0.20849108366253008), (3605, 0.08742798232800401), (3607, 0.11694407146770755), (3609, 0.06606226339139286), (3623, 0.08052435314786263), (3632, 0.06794928857454885), (3637, 0.14921429183063345), (3638, 0.05842675256434094), (3639, 0.06011275389123233), (3647, 0.1032199517615231), (3648, 0.14264810181682472), (3653, 0.14485691236862355), (3655, 0.06703182998873464), (3663, 0.05601170109582847), (3684, 0.06849002624261351), (3686, 0.061027072950040555), (3690, 0.07484183953518907), (3691, 0.06505850907939342), (3696, 0.06968784625286016), (3700, 0.0574291232571854), (3701, 0.06836993870241911), (3712, 0.07451833275345858), (3719, 0.06970804909830486), (3722, 0.05746577260736478), (3730, 0.05050110653752683), (3731, 0.05787866932553884), (3739, 0.11953572774163415), (3741, 0.07717918292733794), (3751, 0.13984859427052682), (3757, 0.07108961860796084), (3760, 0.13647132558538347), (3764, 0.07693409623653497), (3765, 0.07342737233631813), (3793, 0.17489150411240825), (3797, 0.1022822880985684), (3799, 0.04652004840542936), (3800, 0.05244539716351593), (3801, 0.06609366785188132), (3804, 0.14542851691997663), (3808, 0.06715990125677472), (3809, 0.05954686147580358), (3811, 0.07825343899867925), (3812, 0.1630527514922513), (3818, 0.04682260722776775), (3820, 0.06521545799410489), (3821, 0.39214486375656915), (3822, 0.16561412142950635), (3836, 0.0654242144692615), (3842, 0.05398121200840802), (3844, 0.060806001751244856), (3848, 0.0759055215752624), (3854, 0.07506251805356301), (3856, 0.12469432928668883), (3867, 0.16155452516128735), (3875, 0.06283847638845205), (3880, 0.07453352252319632), (3881, 0.06952225012368801), (3884, 0.12484648261075361), (3885, 0.05612827371685981), (3889, 0.05428214995468086), (3893, 0.09825684431816221), (3894, 0.07315779841645027), (3903, 0.11617770513840811), (3910, 0.06668851685249555), (3913, 0.14663376434432207), (3920, 0.08142245176881817), (3934, 0.14282903258050178), (3935, 0.18517069765135427), (3936, 0.1759621479265568), (3937, 0.04412681815806741), (3939, 0.11819469523055061), (3940, 0.07981548075724473), (3942, 0.06514073551873627), (3943, 0.1853549441790518), (3944, 0.012470666933511778), (3954, 0.05859664256820923), (3959, 0.13350408606497913), (3960, 0.055005506809349215), (3961, 0.07451750455094426), (3995, 0.05965577273259036), (3997, 0.055143478402167), (3998, 0.055143478402167), (4000, 0.15465502767734896), (4001, 0.06605151494177015), (4006, 0.1321336484686715), (4009, 0.05288866354853568), (4011, 0.16472213462004426), (4014, 0.1800823286413117), (4017, 0.10988195184236163), (4019, 0.06835599173549896), (4020, 0.06835599173549896), (4024, 0.11120156896692569), (4040, 0.08881999935141487), (4042, 0.0728783823197062), (4047, 0.09648638555938757), (4067, 0.11872719045156702), (4078, 0.1286198335221507), (4079, 0.05432171403142009), (4083, 0.06591744652708903), (4090, 0.0546782961215319), (4094, 0.06322157907461284), (4104, 0.04338141748676667), (4108, 0.06535971075337994), (4127, 0.05152941499581539), (4133, 0.07465796388069619), (4139, 0.06619803647417079), (4141, 0.12914641565081963), (4142, 0.06907697798239806), (4145, 0.07334516174939812), (4147, 0.3448786700113904), (4149, 0.10831175652675282), (4156, 0.16093800728988694), (4158, 0.17663394730949195), (4161, 0.05986502493357913), (4164, 0.13439916065666493), (4165, 0.07094769906345842), (4166, 0.06574100291006545), (4168, 0.08156054342772792), (4178, 0.09165426514296199), (4187, 0.05172791875229618), (4189, 0.18822169101305905), (4191, 0.12609815953373435), (4192, 0.061071215535779204), (4193, 0.2164507710378507), (4194, 0.0868540123451891), (4197, 0.09192891399950424), (4200, 0.17036472350619353), (4201, 0.08436275925667154), (4204, 0.12441451080989663), (4205, 0.05904976515090686), (4206, 0.08191904039796102), (4208, 0.05979127817082185), (4211, 0.0677339721898981), (4216, 0.06858677334542196), (4220, 0.09149703320162574), (4221, 0.2874256296012188), (4230, 0.3829895715292631), (4242, 0.0645258749867125), (4252, 0.08883987364548263), (4253, 0.16153759465919412), (4263, 0.06938257950214428), (4274, 0.119036759938551), (4278, 0.10682655647974901), (4279, 0.0751803282569954), (4287, 0.11137254060808231), (4291, 0.14906754292021174), (4294, 0.16626266496977185), (4295, 0.05845605686863254), (4297, 0.07937094782417844), (4299, 0.06710942777783103), (4302, 0.32493293869274537), (4303, 0.07544107059741066), (4305, 0.1362368971626608), (4323, 0.0683755227982301), (4330, 0.13259572597976058), (4336, 0.22112398451957357), (4343, 0.07159207308921159), (4345, 0.09723204461817403), (4347, 0.14248242629069777), (4351, 0.06568737379839415), (4354, 0.10771624526219224), (4359, 0.05451318684549191), (4360, 0.06291323399523671), (4383, 0.036638581174916064), (4396, 0.06691699039577796), (4399, 0.07715776541021203), (4401, 0.2002445923674432), (4411, 0.06878781124633132), (4418, 0.10199387060666384), (4424, 0.08652036801743086), (4430, 0.11545830083508234), (4447, 0.09607837157372316), (4448, 0.19673136393758905), (4449, 0.15416042206341507), (4471, 0.1963468638349008), (4479, 0.13438651624893416), (4481, 0.06655483643159103), (4485, 0.061995495070784626), (4504, 0.06596998581225987), (4506, 0.08995804276978657), (4507, 0.06648781267225408), (4509, 0.0667325708723642), (4511, 0.05776553483448205), (4512, 0.0667325708723642), (4513, 0.12442422468387844), (4514, 0.12358794092220166), (4515, 0.08823683239395583), (4520, 0.17448816879150572), (4529, 0.07012822941447094), (4530, 0.07643546276507035), (4536, 0.06924730623935116), (4538, 0.049876937286733834), (4539, 0.046064691563745104), (4542, 0.19549516598403094), (4545, 0.1796287192440189), (4562, 0.09406994551899649), (4569, 0.08528387067016296), (4571, 0.06296018112144958), (4575, 0.1439710240168222), (4577, 0.2379100326092085), (4578, 0.08221774590054597), (4580, 0.15365375231719972), (4583, 0.07712769194655471), (4585, 0.06694868378070651), (4587, 0.06710062259315988), (4589, 0.06479316885592415), (4590, 0.06856234289628521), (4606, 0.07345701638617792), (4611, 0.0482220043411724), (4641, 0.06345050805273865), (4642, 0.04815487109695643), (4650, 0.050022987291093134), (4651, 0.08879046456913993), (4657, 0.08125112627751897), (4659, 0.09269085656281205), (4662, 0.20670653266315756), (4665, 0.0677194345105292), (4700, 0.061179547233649816), (4707, 0.06801136320110757), (4708, 0.055302238891556145), (4710, 0.04703322350041007), (4711, 0.130898422915229), (4712, 0.06756965227069059), (4716, 0.12312993750284053), (4718, 0.03809208648438946), (4720, 0.1383076795292817), (4724, 0.06916832410585019), (4734, 0.052331131248313484), (4737, 0.1232039621976688), (4740, 0.05534242247729936), (4758, 0.07243282160190938), (4766, 0.08017136115025192), (4768, 0.24389567519848568), (4770, 0.15009105199149464), (4780, 0.11726548611043307), (4782, 0.05949212002905563), (4783, 0.051145153575370354), (4784, 0.0599320541766642), (4797, 0.15272881669104962), (4806, 0.12238983201751229), (4809, 0.09188001227920221), (4817, 0.077135032746572), (4820, 0.07801387323782132), (4825, 0.06746503642518537), (4826, 0.06722216325137174), (4850, 0.07418186826176654), (4851, 0.0694205666482734), (4858, 0.19027463978847123), (4861, 0.06297290270088061), (4863, 0.05737881685692884), (4864, 0.07253752519701014), (4866, 0.06686328783976325), (4867, 0.06659273814149634), (4868, 0.12353832844643403), (4871, 0.13131321536496088), (4874, 0.054713733818221734), (4875, 0.228940217522185), (4876, 0.0790412681177041), (4878, 0.05399610470101163), (4879, 0.13353456959893362), (4880, 0.07979491438276044), (4884, 0.0800471105644548), (4890, 0.0583724622529487), (4896, 0.057581017701216826), (4900, 0.06025597537811445), (4904, 0.08034146197191956), (4912, 0.11542740688485703), (4914, 0.06944543524040113), (4917, 0.05559882590419344), (4924, 0.128203084158821), (4930, 0.056524055264214244), (4955, 0.09322262424520533), (4976, 0.13482080598981547), (4983, 0.04554625672076325), (4987, 0.1854378063389851), (4989, 0.12462339380820195), (4992, 0.11566235138461041), (4993, 0.07503045498616402), (4999, 0.06997534828363072), (5019, 0.12549354231699572), (5020, 0.08133553225928682), (5023, 0.06517352075669183), (5029, 0.13573997977785335), (5041, 0.13816226495611916), (5056, 0.11990998845406006), (5060, 0.052083470964011905), (5064, 0.062488028923549384), (5065, 0.0766935475361097), (5068, 0.06194903053646448), (5072, 0.14583901902624855), (5074, 0.0820274916916744), (5076, 0.41630100209697235), (5079, 0.07419743436418377), (5080, 0.058596741027354064), (5082, 0.09887827346373745), (5093, 0.044246740369946934), (5101, 0.05763335950055155), (5104, 0.202368553615026), (5107, 0.05116566053095969), (5112, 0.05162551685952702), (5118, 0.052991098283099454), (5124, 0.061221098468771426), (5130, 0.09066258845828215), (5132, 0.08938514244487657), (5135, 0.06993475184834959), (5136, 0.11380728251446208), (5137, 0.06615664874636296), (5138, 0.0728508877734966), (5139, 0.07923844905174234), (5145, 0.06605963992781556), (5149, 0.07505805901997921), (5150, 0.0663621446423663), (5153, 0.05506008649444216), (5155, 0.05705661909800885), (5158, 0.06426671405806796), (5165, 0.06408159556980349), (5167, 0.06270650462902971), (5171, 0.043605441706477434), (5175, 0.08621725823500251), (5183, 0.05930947919502499), (5184, 0.07565501764704492), (5185, 0.11292637841011086), (5186, 0.18057659853983288), (5189, 0.06432860130762753), (5206, 0.1270541798728893), (5208, 0.059163647277130235), (5209, 0.06446786042142634), (5215, 0.1337480512687644), (5217, 0.21656178774732757), (5221, 0.06468594866360337), (5234, 0.13520227668412438), (5246, 0.06108573240275834), (5247, 0.07185422178474016), (5249, 0.07142849062915967), (5255, 0.04773839498090825), (5263, 0.14695023815898686), (5270, 0.10097563506150373), (5271, 0.07189725982251713), (5274, 0.09353286434036578), (5275, 0.06400444588919812), (5279, 0.20225639326784173), (5280, 0.06250077086068295), (5298, 0.07507227473798449), (5299, 0.07587084529727585), (5301, 0.05979557866952981), (5304, 0.06133529493841131), (5308, 0.09686678310507742), (5309, 0.051542696511052734), (5316, 0.06927102076930232), (5319, 0.11644169029792575), (5320, 0.07930352229272938), (5321, 0.05422430212611695), (5326, 0.07456735421659139), (5331, 0.14688676139124227), (5332, 0.1203714263282066), (5333, 0.07290597273504695), (5338, 0.0777753926498543), (5339, 0.11641133480080552), (5344, 0.10276164984114068), (5345, 0.06540100938098069), (5354, 0.062336519334915026), (5358, 0.18586331298736802), (5361, 0.07834373414791206), (5369, 0.27686619465697115), (5371, 0.09670797825967013), (5372, 0.11848676833780528), (5376, 0.05439950805752912), (5377, 0.08191930468685397), (5399, 0.08453361720324779), (5422, 0.09267798088872933), (5428, 0.07566152970141753), (5429, 0.08062768993574922), (5430, 0.05056229418520432), (5447, 0.06558616118829032), (5454, 0.18957448751297026), (5457, 0.06757209101375973), (5462, 0.04981562264945268), (5492, 0.05529199710659116), (5494, 0.10344796892033384), (5496, 0.07745783132753689), (5497, 0.06316643606304882), (5502, 0.18999128224514525), (5504, 0.07963455342103257), (5525, 0.10927440187433789), (5527, 0.1386930295958663), (5531, 0.049280916298758096), (5532, 0.08048653462159558), (5539, 0.05304096467051209), (5542, 0.06555254119640617), (5545, 0.09305447693717768), (5551, 0.08198682531849187), (5552, 0.1574248030699816), (5553, 0.2903205316215856), (5554, 0.0876889431673006), (5556, 0.07512637607497719), (5557, 0.05324770904274647), (5558, 0.07761208458667565), (5561, 0.10344796892033384), (5562, 0.08314931892481016), (5582, 0.037381348552616066), (5587, 0.11289280604227693), (5591, 0.13948092386418243), (5596, 0.06251124275834297), (5601, 0.21032377797123988), (5603, 0.05539356262420019), (5606, 0.05123618620984275), (5608, 0.08114781794008225), (5611, 0.06105322473065888), (5622, 0.05803419464393731), (5623, 0.06507629385857867), (5643, 0.07712745258504174), (5644, 0.10607495718639785), (5645, 0.05841663816475478), (5647, 0.07289482950896947), (5648, 0.07274714915624975), (5650, 0.08853157120560198), (5672, 0.07639928602899547), (5680, 0.08818479550514118), (5681, 0.0639087953374232), (5682, 0.0745278047609791), (5690, 0.06937338044485318), (5701, 0.10315735524290263), (5718, 0.06152676467843143), (5724, 0.0782266661424002), (5727, 0.09796535345663777), (5741, 0.08817707633033697), (5743, 0.04779198990094605), (5744, 0.07280556633588323), (5755, 0.07315534093118692), (5756, 0.05793662641977059), (5757, 0.16758498023943263), (5763, 0.08460021690600845), (5798, 0.12813866629690981), (5799, 0.06442417626709876), (5800, 0.0633367417807402), (5803, 0.08452416106328363), (5808, 0.0742083867807359), (5809, 0.06930936626302198), (5810, 0.0808455771254346), (5815, 0.07824475186982151), (5817, 0.21304048037609144), (5839, 0.07159537277813144), (5840, 0.018615382152717803), (5841, 0.05695153826884513), (5844, 0.06913997392752418), (5850, 0.08536805850946344), (5863, 0.06447116125826499), (5881, 0.0483743113897229), (5884, 0.06431283051980842), (5885, 0.1410437873207837), (5889, 0.059011355490062166), (5900, 0.08688146864533071), (5905, 0.10704315614961894), (5909, 0.06497847990733215), (5921, 0.08064322575349675), (5927, 0.08381833463799884), (5932, 0.07420622631432462), (5942, 0.0747828641748037), (5944, 0.09435796637907705), (5945, 0.12441439811009869), (5948, 0.07324977841522398), (5952, 0.07175151793580298), (5989, 0.06638294780993609), (5990, 0.09542747059070081), (5991, 0.042328472425558206), (5992, 0.04658759119865414), (5993, 0.052019435172412046), (5995, 0.10141447378183763), (5996, 0.07216711012424876), (5998, 0.0499699244775674)]\n",
      "Term ID: 4, Postings List: [(1, 0.16020618469668868), (8, 0.08750401428202305), (18, 0.08120702221007091), (60, 0.07656484706834624), (80, 0.07372752837338713), (82, 0.10191827765447341), (86, 0.0978243513320503), (90, 0.09122730839911057), (100, 0.12850174877569345), (103, 0.10142985232889389), (129, 0.12040257294099038), (138, 0.10538431646278441), (191, 0.21724864327469826), (250, 0.10917782626360162), (295, 0.12383083046435078), (301, 0.0721721658804589), (308, 0.03953854198282736), (377, 0.3009389029220752), (378, 0.11457165542416851), (408, 0.08592245318193589), (452, 0.10888754125042827), (470, 0.10042922901884296), (499, 0.11985605176635422), (504, 0.11143272326424265), (511, 0.14570103789641428), (515, 0.07033776475285014), (521, 0.09145761862174358), (526, 0.11935372330174739), (529, 0.1977141108718109), (530, 0.06588446039719852), (535, 0.1808642305600007), (573, 0.12161513598221765), (584, 0.015342114244553229), (605, 0.10894831714456374), (615, 0.08203413119816653), (617, 0.10206006154440915), (620, 0.09913586148016755), (625, 0.0819304971474245), (627, 0.12661107028722743), (693, 0.0750974545894785), (723, 0.10209350971036833), (812, 0.08664309692649343), (818, 0.025689050999445826), (821, 0.042396162961863486), (825, 0.08361209328687197), (829, 0.08195338488613257), (834, 0.08507784037041947), (966, 0.1202710250276071), (980, 0.10951679466968106), (1000, 0.11279014169052035), (1016, 0.12389156063312813), (1042, 0.09317457520913977), (1059, 0.10765926952716227), (1067, 0.10985825638021297), (1076, 0.0821834401950677), (1108, 0.10372494814770208), (1124, 0.19371716769155642), (1138, 0.08234549964601194), (1144, 0.17932692652811008), (1147, 0.07766871051050338), (1167, 0.172165207542954), (1186, 0.06955424115178467), (1198, 0.2293017832685191), (1220, 0.13831159196349338), (1226, 0.26781832145215373), (1232, 0.08399105070050715), (1276, 0.1763162833311818), (1281, 0.11710653145413573), (1286, 0.2609500322529353), (1287, 0.07953142139875058), (1308, 0.09779071264915797), (1311, 0.16075394661163214), (1431, 0.06376268987751431), (1439, 0.18257453523365255), (1440, 0.06376268987751431), (1458, 0.19085885641178651), (1464, 0.1292097789294248), (1465, 0.08755571877223171), (1493, 0.12793525841200315), (1505, 0.08647635825378751), (1507, 0.10290366318136038), (1513, 0.08663196375541142), (1514, 0.10430278288759065), (1533, 0.14994395069095237), (1545, 0.08149800638675046), (1571, 0.2143885266903646), (1573, 0.11760975916735013), (1604, 0.10257308486818253), (1611, 0.09048916687779841), (1612, 0.11259923940668805), (1619, 0.11193767564843272), (1632, 0.12922917321076788), (1644, 0.24569625240663914), (1647, 0.12365869361535095), (1648, 0.192717355059707), (1689, 0.076944081488769), (1690, 0.07854203558382654), (1692, 0.05806546884346038), (1702, 0.08521691921689671), (1814, 0.19916548591908168), (1880, 0.04207149790830325), (1901, 0.08312250641442978), (1903, 0.10724641295236949), (1912, 0.10616952097468656), (1915, 0.09771290429835348), (1928, 0.07451122173209747), (1964, 0.2779206620705071), (1967, 0.09852840341032694), (1968, 0.258462902235235), (1972, 0.09684699658831719), (1974, 0.27901409401447724), (1976, 0.19434294943548497), (2051, 0.08922385849525398), (2108, 0.07403801850438796), (2112, 0.0683726460608195), (2229, 0.08769623451766519), (2253, 0.09844386852536507), (2254, 0.07059547834800622), (2262, 0.12128713767955047), (2264, 0.08364057132749105), (2265, 0.09968224383971616), (2274, 0.09838135839149904), (2283, 0.21567016648763285), (2286, 0.25355431696481046), (2290, 0.25355431696481046), (2291, 0.08671967660627387), (2293, 0.25355431696481046), (2327, 0.1568440606552428), (2337, 0.10247429903684434), (2344, 0.08206975298558518), (2359, 0.15750887168340516), (2363, 0.09295806730938244), (2393, 0.10233349055531157), (2407, 0.10785066472733153), (2423, 0.10191241751475333), (2447, 0.10771619080999556), (2450, 0.1001646094251667), (2452, 0.0740264286849775), (2453, 0.12975450377828962), (2457, 0.10760900164414731), (2472, 0.11370993697470652), (2501, 0.06035761081167572), (2508, 0.0825161881296232), (2513, 0.09199262518723958), (2629, 0.09964314235611751), (2632, 0.09955469762029436), (2639, 0.1023746042552056), (2676, 0.07811545071949377), (2677, 0.1467460247128866), (2732, 0.09801038046571173), (2735, 0.07373120393326203), (2737, 0.05095714711642795), (2747, 0.10473924970223743), (2749, 0.1459681351226655), (2848, 0.26650176700767036), (2884, 0.21160031316400046), (2915, 0.15241347684787462), (2916, 0.09981504236459625), (2924, 0.0982337773961245), (2997, 0.27331331506614226), (3002, 0.08767361688460136), (3012, 0.06225023684178101), (3052, 0.10047013100355301), (3064, 0.09537538593977495), (3077, 0.10584272528631483), (3082, 0.17879528149925755), (3083, 0.08892426156189912), (3085, 0.2197037461753384), (3087, 0.07683610606266787), (3088, 0.242286589001719), (3089, 0.08093838550301775), (3101, 0.07691725487695822), (3119, 0.12827932231478906), (3227, 0.0984944486832559), (3278, 0.1308613895611764), (3298, 0.09324182153870654), (3309, 0.09020080220565059), (3329, 0.09537538593977495), (3330, 0.09780668515193106), (3333, 0.365151939568598), (3339, 0.10513179877478707), (3354, 0.27845218789714415), (3368, 0.08927275839440793), (3375, 0.20672107619433402), (3392, 0.08379648287530471), (3393, 0.08364288742970398), (3399, 0.08541803071760136), (3402, 0.08379648287530471), (3403, 0.08379648287530471), (3447, 0.08119300121238224), (3448, 0.11376498715768074), (3524, 0.10114172923600305), (3528, 0.12429819341742004), (3529, 0.1148327894293545), (3533, 0.10099786506770603), (3535, 0.11996965811877287), (3537, 0.16182455500265577), (3567, 0.08864333602259683), (3602, 0.07030929042734624), (3613, 0.10333172211373746), (3652, 0.14451166312674563), (3674, 0.1088997191243667), (3679, 0.10677034734133894), (3712, 0.10936855239807639), (3739, 0.1754393720295136), (3793, 0.25668355590804004), (3812, 0.11965406857819928), (3818, 0.1374405621485672), (3824, 0.14666955760716466), (3827, 0.0804727192376678), (3864, 0.06884776284716652), (3944, 0.03660572478101879), (3945, 0.10891569270076065), (3960, 0.1614602053313343), (3999, 0.1716561827489511), (4011, 0.16117216391049008), (4017, 0.1612707848340376), (4114, 0.06944581090346363), (4142, 0.20276484475205955), (4167, 0.10517596285996086), (4194, 0.012747329749828722), (4204, 0.09129991534842602), (4211, 0.09941132890197275), (4223, 0.11142932990934985), (4226, 0.08642955394385007), (4242, 0.09470289093643812), (4243, 0.10309497967857512), (4249, 0.11177777180262231), (4267, 0.06735068796544505), (4268, 0.17556474716115378), (4269, 0.10127368131733921), (4279, 0.11034014539057391), (4312, 0.09401659344067734), (4346, 0.22554930609432938), (4349, 0.0871886101193541), (4352, 0.09005362864203788), (4379, 0.13581939036785579), (4385, 0.08135220452662191), (4395, 0.1843136046842641), (4408, 0.1017786955056084), (4436, 0.09075556105914925), (4438, 0.08689582046547124), (4452, 0.08312250641442978), (4454, 0.10724641295236949), (4496, 0.09134277528754237), (4503, 0.10458164309227168), (4525, 0.09611274986084067), (4531, 0.07751901467812683), (4534, 0.09197991121650348), (4547, 0.08738484129166835), (4553, 0.10353485226135369), (4566, 0.1464045666213822), (4654, 0.10054264895135345), (4668, 0.07739391089195137), (4674, 0.09299427617746356), (4675, 0.15780249301593458), (4729, 0.06004180841362982), (4771, 0.08676351352718667), (4777, 0.10099514631256573), (4788, 0.263231229442673), (4789, 0.09426917226024012), (4791, 0.18024472091207014), (4793, 0.07237897328175916), (4795, 0.2707343178964518), (4800, 0.2781612928951185), (4875, 0.11200313287980794), (4915, 0.05551036415779573), (4931, 0.09640385044174736), (4935, 0.09286431466579621), (4973, 0.0976824597264239), (5029, 0.099610958419886), (5035, 0.10442920349254561), (5048, 0.14414629371092663), (5060, 0.07644150925983843), (5061, 0.11663736090212169), (5063, 0.08149713903821414), (5089, 0.11136974720196309), (5099, 0.09318859526585499), (5100, 0.08240360110557246), (5165, 0.09405083398760165), (5177, 0.10895272434027282), (5180, 0.09603560646508522), (5187, 0.14666955760716466), (5188, 0.17400308126780475), (5190, 0.10991778075121586), (5267, 0.09258589976048553), (5276, 0.18404637014958117), (5278, 0.06150768061849231), (5304, 0.09002016242790624), (5330, 0.12978693182491347), (5350, 0.09952552047609096), (5358, 0.09092886154870651), (5369, 0.10158726651124511), (5429, 0.11833509158945284), (5440, 0.10393096664682328), (5487, 0.12477821506320712), (5492, 0.24345173030454728), (5646, 0.18704428475404558), (5766, 0.09466044760750884), (5767, 0.08819723790891239), (5768, 0.09476924872467107), (5790, 0.14015318193242837), (5803, 0.12405383744611669), (5809, 0.10172349240412881), (5827, 0.1078552936152463), (5840, 0.027321295621515907), (5841, 0.0835862406894517), (5863, 0.09462258906902513), (5865, 0.2568977567975927), (5886, 0.09028701281148636), (5896, 0.1580126295839025), (5923, 0.20628659137227073), (5959, 0.18670492866485613), (5960, 0.07869918805330241), (5963, 0.0809214300888568), (5966, 0.17263266197644775), (5969, 0.06505697972511285), (5970, 0.10771637554760828), (5991, 0.12424872063956187), (5992, 0.06837535437041412)]\n",
      "Term ID: 5, Postings List: [(1, 0.11852018719255626), (131, 0.1313264429360516), (355, 0.15196357152761275), (377, 0.1113169731099154), (812, 0.12819674953389046), (818, 0.11402822452895132), (825, 0.1237120897259139), (826, 0.08512472076002768), (980, 0.162040573271921), (1067, 0.16254579853432838), (1071, 0.13521603258002335), (1076, 0.12159826082231144), (1198, 0.16963696082036195), (1226, 0.39626282408760893), (1276, 0.26087680628648513), (1308, 0.14469071329318337), (1644, 0.12117703563432325), (1648, 0.1425718803563949), (1702, 0.12608658319504065), (2229, 0.12975496733530067), (2749, 0.21597381813492797), (2758, 0.24426643129454542), (2912, 0.12490130191199489), (2915, 0.22551031773059643), (2916, 0.14768590273942647), (2924, 0.1453462699665829), (3077, 0.15660443618521083), (3083, 0.1315719508111344), (3086, 0.15511464702531133), (3087, 0.11368636848740496), (3088, 0.11949539458415682), (3089, 0.11975608331279636), (3090, 0.3147016969534072), (3393, 0.12375765260577143), (3399, 0.12638414689715638), (3447, 0.12013281160943706), (3448, 0.168326180408262), (3567, 0.131156294604499), (3615, 0.1570955000270541), (3793, 0.126595957798878), (4103, 0.11492318036710901), (4104, 0.18841093940893996), (4222, 0.12145365930465102), (4267, 0.09965178510835583), (4268, 0.12988241831829753), (4547, 0.12929423127188946), (4812, 0.13220240782656092), (5276, 0.2723142091366429), (5278, 0.09100649684012291), (5440, 0.15377580641353875), (5492, 0.12007004058623816), (5630, 0.1687806850030438), (5957, 0.14156169693641568), (5960, 0.11644297650104864), (5964, 0.13375855284933336), (5966, 0.12771326807223302), (5969, 0.19251604873559122), (5970, 0.15937668096617616)]\n"
     ]
    }
   ],
   "source": [
    "for term_id in list(inverted_index_tfidf.keys())[:5]:\n",
    "    print(f\"Term ID: {term_id}, Postings List: {inverted_index_tfidf[term_id]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term ID: 1, Postings List: [(1, 0.0877462699718074), (45, 0.11712786492027691), (53, 0.06736352759705212), (88, 0.10474995073485001), (103, 0.11110796031378978), (135, 0.16984840797741835), (138, 0.11543974660709833), (170, 0.13577607583088047), (178, 0.12475318280833658), (194, 0.10151259207866951), (359, 0.08667479936917441), (368, 0.13649591129163866), (445, 0.10150179337929957), (449, 0.0934016107339302), (496, 0.15660031059364365), (497, 0.10791850730824007), (515, 0.0770491664463767), (533, 0.10585424489673981), (539, 0.13471618825133916), (559, 0.09277924544757649), (579, 0.10736507632299537), (584, 0.03361201818742781), (644, 0.09468598313071894), (666, 0.08541041701682388), (677, 0.1041745850658261), (691, 0.09076263666699377), (695, 0.15132232896124062), (730, 0.09251485250457361), (735, 0.13749833851757262), (772, 0.11335085606483787), (778, 0.1221525852746661), (826, 0.0630219788376543), (855, 0.09976791569550218), (885, 0.10629745899268139), (940, 0.08662779356494463), (957, 0.11457213765135249), (979, 0.1146061386416074), (992, 0.085139376485034), (1010, 0.09439363778890482), (1052, 0.1172988553187549), (1056, 0.11098836677109214), (1091, 0.0662358971862704), (1140, 0.07631827333068521), (1141, 0.10479125429180883), (1144, 0.09821886051491026), (1147, 0.08507960730379527), (1150, 0.13922365392705585), (1173, 0.08834844967080742), (1177, 0.09880822159905968), (1247, 0.13760075785182688), (1249, 0.12726257779596536), (1258, 0.10546056616590486), (1313, 0.12708514326054723), (1340, 0.08662779356494463), (1347, 0.08662779356494463), (1372, 0.06939844408096525), (1404, 0.09329208080638828), (1428, 0.12807758300527486), (1458, 0.10453499515593416), (1477, 0.09882090923700283), (1536, 0.12628058930148972), (1537, 0.139211174967308), (1538, 0.11551651713097064), (1544, 0.139211174967308), (1605, 0.09879747392215174), (1612, 0.12334309412966923), (1627, 0.11842729293301475), (1644, 0.08971326433932983), (1648, 0.10555291044061192), (1663, 0.10418489271754408), (1668, 0.09001569766122526), (1683, 0.11707083208627571), (1686, 0.09806356069420921), (1705, 0.07970051049501146), (1724, 0.19139307655868432), (1731, 0.06643388332209864), (1816, 0.0812048185535491), (1829, 0.10769840551244672), (1852, 0.11060309917673018), (1853, 0.08962396735577897), (1965, 0.30389706926091975), (1987, 0.11700408658735073), (2013, 0.09685476807992706), (2025, 0.1153502474681442), (2031, 0.13443050415769864), (2038, 0.12469451591240908), (2059, 0.12871984542795242), (2062, 0.10997285303816662), (2063, 0.10146973186495326), (2070, 0.10057476542039333), (2093, 0.11546000492241117), (2096, 0.28118926204853223), (2183, 0.07776716743377941), (2186, 0.09288204895423793), (2198, 0.11494774004643006), (2225, 0.08384729354267074), (2229, 0.09606392517325874), (2292, 0.22310788211614874), (2297, 0.14000848707284377), (2303, 0.06610122359509062), (2307, 0.13297984003830124), (2312, 0.12305168450773565), (2313, 0.12442427538924289), (2342, 0.09837922968235817), (2398, 0.07473949529894883), (2432, 0.10754575716064661), (2448, 0.11123838366806059), (2476, 0.20314037801407045), (2509, 0.11264851181606038), (2540, 0.11474447825854577), (2564, 0.08906932317994444), (2578, 0.08962086462931586), (2584, 0.12343373252396567), (2589, 0.10091025285316421), (2596, 0.23103746651406334), (2605, 0.08662779356494463), (2639, 0.11214285740892353), (2649, 0.12043679203720936), (2673, 0.15951399014949813), (2677, 0.08037402754534614), (2682, 0.08206229113588878), (2714, 0.09864440191764158), (2741, 0.14097770387841235), (2848, 0.09731016747820595), (2943, 0.10527356282837234), (2979, 0.13110678962408506), (3052, 0.11005666548805634), (3069, 0.07744280443617482), (3107, 0.13607035583810986), (3129, 0.12014548102972722), (3136, 0.11321162008934806), (3168, 0.12459868820289845), (3169, 0.13495447064232022), (3180, 0.14033359788646863), (3247, 0.08905649030030278), (3253, 0.12765053364133627), (3283, 0.10546638216410284), (3286, 0.09084203834065856), (3295, 0.11449924528355064), (3346, 0.10603390520286528), (3354, 0.10167373125959085), (3358, 0.1080863562945368), (3393, 0.09162382083467717), (3399, 0.09356834254553849), (3424, 0.1232988883133375), (3431, 0.07809653693874524), (3464, 0.08423649940693706), (3484, 0.09775515563964886), (3485, 0.08012415516258813), (3497, 0.25002065376536803), (3508, 0.12864696242314372), (3521, 0.1029841098778101), (3524, 0.11079234544858621), (3526, 0.11840731803791993), (3543, 0.16854233432542623), (3597, 0.11960838956164), (3606, 0.11155119741959639), (3651, 0.17841445058117447), (3672, 0.08935644327840568), (3673, 0.08935644327840568), (3675, 0.08935644327840568), (3681, 0.08008060328191627), (3739, 0.09608961433624504), (3759, 0.145375697401958), (3777, 0.18371978743520245), (3789, 0.1303471450598944), (3793, 0.09372515647745747), (3817, 0.08433312104809758), (3882, 0.13476214556850113), (3944, 0.06014778671429178), (3962, 0.0774502372589919), (4001, 0.10619192633013626), (4011, 0.08827534488262839), (4017, 0.0883293603889514), (4162, 0.10032791965561268), (4276, 0.08348804187343886), (4281, 0.09658882005261565), (4289, 0.12574066923193084), (4327, 0.08877431182116063), (4328, 0.11868268884398568), (4352, 0.09864625420954136), (4370, 0.11072214236344391), (4374, 0.08123291537725982), (4399, 0.12404759750722516), (4432, 0.09111507716179267), (4433, 0.10772195937408552), (4435, 0.10772195937408552), (4438, 0.1903742764093812), (4463, 0.07546474448031633), (4495, 0.11915077703741055), (4579, 0.13110925009773394), (4593, 0.0785222071736443), (4677, 0.09671812060038631), (4682, 0.10518389105291168), (4693, 0.11038678409965588), (4721, 0.1058260166619198), (4736, 0.09624410558233919), (4767, 0.22098085502406356), (4838, 0.09753982832744167), (4932, 0.11403043247545999), (4944, 0.09578715223869076), (4961, 0.13108698788040798), (4969, 0.09703471039608275), (4976, 0.10837662928747047), (4987, 0.09937696804749899), (5001, 0.12684945973613485), (5037, 0.08295311749841222), (5054, 0.10146066390357637), (5093, 0.07113609124417987), (5175, 0.13861266835361938), (5195, 0.10093451862772894), (5198, 0.07071509555231367), (5202, 0.1269875518640285), (5225, 0.10113158951065204), (5256, 0.10976718777472218), (5290, 0.28263228524515177), (5306, 0.12325123455612065), (5332, 0.0645075975833264), (5445, 0.10398029264686795), (5492, 0.08889370196225632), (5495, 0.18569327909521324), (5505, 0.11771732757028913), (5510, 0.10101522205216935), (5534, 0.09534028852473225), (5550, 0.12068634323998421), (5575, 0.12443580131359246), (5579, 0.12274777817415738), (5603, 0.17811398047534963), (5663, 0.054695309876829176), (5677, 0.07651013894724937), (5722, 0.10558786674551329), (5730, 0.08855459570915615), (5750, 0.1095307049629265), (5755, 0.1176128447874236), (5794, 0.1262853226317013), (5810, 0.2599530859448118), (5814, 0.10502664556190856), (5825, 0.15215254725337896), (5837, 0.10743762715908045), (5872, 0.10256906159242936), (5952, 0.11535589930725128), (5980, 0.0873361151447488), (5994, 0.0995767729307718)]\n",
      "The term for ID 1 is 'choos'.\n"
     ]
    }
   ],
   "source": [
    "# Reverse the vocabulary dictionary to map from IDs to terms\n",
    "reverse_vocabulary = {v: k for k, v in vocabulary.items()}\n",
    "term_id = 1\n",
    "term = reverse_vocabulary.get(term_id)\n",
    "\n",
    "print(f\"Term ID: {term_id}, Postings List: {inverted_index_tfidf[term_id]}\")\n",
    "if term is not None:\n",
    "    print(f\"The term for ID {term_id} is '{term}'.\")\n",
    "else:\n",
    "    print(f\"No term found for ID {term_id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    return vectorizer.transform([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"cyber security\"\n",
    "query= stem(punct(stopless(query)))\n",
    "query_tfidf = process_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(query, inverted_index, vocabulary):\n",
    "    query_terms = query.split()\n",
    "    document_sets = [set() for _ in query_terms]\n",
    "\n",
    "    for i, term in enumerate(query_terms):\n",
    "        term_id = vocabulary.get(term)\n",
    "        if term_id in inverted_index:\n",
    "            document_sets[i] = {doc_id for doc_id, _ in inverted_index[term_id]}\n",
    "\n",
    "    # Find the intersection of documents that contain all query terms\n",
    "    common_documents = set.intersection(*document_sets)\n",
    "    return common_documents\n",
    "\n",
    "common_documents = search_documents(query, inverted_index_tfidf, vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6818716179396056, 5758),\n",
       " (0.6805071556894349, 2142),\n",
       " (0.6026335890795351, 1657),\n",
       " (0.5051623042065325, 5756),\n",
       " (0.4824589973002299, 5748),\n",
       " (0.4626623485806959, 1659),\n",
       " (0.46212159974949474, 1660),\n",
       " (0.4606974032203577, 3851),\n",
       " (0.4462613878101863, 5759),\n",
       " (0.4454996115633141, 3849)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "def calculate_top_k_similarity(common_documents, query_tfidf, tfidf_matrix, k=10):\n",
    "\n",
    "    top_k_heap = []\n",
    "\n",
    "    for doc_id in common_documents:\n",
    "        doc_tfidf = tfidf_matrix[doc_id]\n",
    "        sim = cosine_similarity(doc_tfidf, query_tfidf)[0][0]\n",
    "        \n",
    "        if len(top_k_heap) < k:\n",
    "            heapq.heappush(top_k_heap, (sim, doc_id))\n",
    "        else:\n",
    "            heapq.heappushpop(top_k_heap, (sim, doc_id))\n",
    "\n",
    "    sorted_top_k = sorted(top_k_heap, key=lambda x: x[0], reverse=True)\n",
    "    return sorted_top_k\n",
    "\n",
    "k = 10 \n",
    "top_k_documents = calculate_top_k_similarity(common_documents, query_tfidf, tfidf_matrix, k)\n",
    "top_k_documents\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>courseName</th>\n",
       "      <th>universityName</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5758</th>\n",
       "      <td>Cyber Security MSc</td>\n",
       "      <td>City, University of London</td>\n",
       "      <td>Key informationWith the demand for graduates w...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.681872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>Applied Cyber Security - MSc</td>\n",
       "      <td>University of Suffolk</td>\n",
       "      <td>IntroductionA conversion course is a programme...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.680507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>Cyber Security (MSc)</td>\n",
       "      <td>University of Gloucestershire</td>\n",
       "      <td>This course is designed for those wishing to d...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.602634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5756</th>\n",
       "      <td>Cyber Security MSc</td>\n",
       "      <td>Buckinghamshire New University</td>\n",
       "      <td>Our MSc in Cyber Security will help you develo...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.505162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5748</th>\n",
       "      <td>Cyber Security MSc</td>\n",
       "      <td>King’s College London</td>\n",
       "      <td>The Cyber Security MSc course aims to provide ...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.482459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>Cyber Security and Data Analytics MSc</td>\n",
       "      <td>Loughborough University London</td>\n",
       "      <td>Our Cyber Security and Data Analytics MSc is a...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.462662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>Cyber Security (MSc)</td>\n",
       "      <td>Sheffield Hallam University</td>\n",
       "      <td>Develop your skills and academic knowledge in ...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.462122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>Cyber Security (Infrastructures Security) - MSc</td>\n",
       "      <td>University of Bristol</td>\n",
       "      <td>Digital technologies drive economic growth yet...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.460697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5759</th>\n",
       "      <td>Cyber Security MSc</td>\n",
       "      <td>Sabanci University</td>\n",
       "      <td>With a curriculum carefully designed to addres...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.446261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>Cyber Security (MSc)</td>\n",
       "      <td>University of Derby</td>\n",
       "      <td>Take our MSc Cyber Security and become part of...</td>\n",
       "      <td>https://www.findamasters.com/masters-degrees/c...</td>\n",
       "      <td>0.445500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           courseName  \\\n",
       "5758                               Cyber Security MSc   \n",
       "2142                     Applied Cyber Security - MSc   \n",
       "1657                             Cyber Security (MSc)   \n",
       "5756                               Cyber Security MSc   \n",
       "5748                               Cyber Security MSc   \n",
       "1659            Cyber Security and Data Analytics MSc   \n",
       "1660                             Cyber Security (MSc)   \n",
       "3851  Cyber Security (Infrastructures Security) - MSc   \n",
       "5759                               Cyber Security MSc   \n",
       "3849                             Cyber Security (MSc)   \n",
       "\n",
       "                      universityName  \\\n",
       "5758      City, University of London   \n",
       "2142           University of Suffolk   \n",
       "1657   University of Gloucestershire   \n",
       "5756  Buckinghamshire New University   \n",
       "5748           King’s College London   \n",
       "1659  Loughborough University London   \n",
       "1660     Sheffield Hallam University   \n",
       "3851           University of Bristol   \n",
       "5759              Sabanci University   \n",
       "3849             University of Derby   \n",
       "\n",
       "                                            description  \\\n",
       "5758  Key informationWith the demand for graduates w...   \n",
       "2142  IntroductionA conversion course is a programme...   \n",
       "1657  This course is designed for those wishing to d...   \n",
       "5756  Our MSc in Cyber Security will help you develo...   \n",
       "5748  The Cyber Security MSc course aims to provide ...   \n",
       "1659  Our Cyber Security and Data Analytics MSc is a...   \n",
       "1660  Develop your skills and academic knowledge in ...   \n",
       "3851  Digital technologies drive economic growth yet...   \n",
       "5759  With a curriculum carefully designed to addres...   \n",
       "3849  Take our MSc Cyber Security and become part of...   \n",
       "\n",
       "                                                    url  Similarity  \n",
       "5758  https://www.findamasters.com/masters-degrees/c...    0.681872  \n",
       "2142  https://www.findamasters.com/masters-degrees/c...    0.680507  \n",
       "1657  https://www.findamasters.com/masters-degrees/c...    0.602634  \n",
       "5756  https://www.findamasters.com/masters-degrees/c...    0.505162  \n",
       "5748  https://www.findamasters.com/masters-degrees/c...    0.482459  \n",
       "1659  https://www.findamasters.com/masters-degrees/c...    0.462662  \n",
       "1660  https://www.findamasters.com/masters-degrees/c...    0.462122  \n",
       "3851  https://www.findamasters.com/masters-degrees/c...    0.460697  \n",
       "5759  https://www.findamasters.com/masters-degrees/c...    0.446261  \n",
       "3849  https://www.findamasters.com/masters-degrees/c...    0.445500  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_document_details(top_k_documents, df):\n",
    "    doc_ids = [doc_id for _, doc_id in top_k_documents]\n",
    "    \n",
    "    if doc_ids:\n",
    "        return df.loc[doc_ids, ['courseName', 'universityName', 'description', 'url']].assign(Similarity=[sim for sim, _ in top_k_documents])\n",
    "    else:\n",
    "        print(\"No matching documents found.\")\n",
    "        return None\n",
    "\n",
    "final_results_df = get_document_details(top_k_documents, df)\n",
    "final_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf = TfidfVectorizer()\n",
    "# df_preprocessed['description'] = [\"\" if pd.isna(doc) else doc for doc in df_preprocessed['description']]\n",
    "# results = tfidf.fit_transform(df_preprocessed['description'])\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# i=0\n",
    "# inverted_index2=dict({})\n",
    "# while(i<len(vocabulary)): #jel ovo dobra granica???\n",
    "#     j=0\n",
    "#     L=list([])\n",
    "#     inverted_index2[i]=list([])\n",
    "#     while(j<6000):\n",
    "#         try:\n",
    "#             L.append((j,results[j, i]))\n",
    "#             j=j+1\n",
    "#         except:\n",
    "#             j=j+1\n",
    "#     inverted_index2[i]=L\n",
    "#     i=i+1\n",
    "# print(inverted_index2)\n",
    "\n",
    "# # results je ovog oblika: {(course_id, word_id): tfidf} -> nama treba ovaj oblik: {word_id1: (course_id1, tfidf1), (course_id2, tfidf2), (course_id3, tfidf3)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
